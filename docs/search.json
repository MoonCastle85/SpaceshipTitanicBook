[{"path":"index.html","id":"chapter-1","chapter":"1 Introduction","heading":"1 Introduction","text":"name Vanja Manborg ever since got dabble data science engineering job, ’ve spent free time RStudio instead things like family, friends going movies. believe learning--methodology attempt get relatively high scores Spaceship Titanic competition Kaggle learn new concepts tricks data-science ’m . competition futuristic version Titanic challenge goal predict high accuracy possible space-faring passengers got transported another dimension spaceships maiden voyage solar system another.formalities:won’t go details packages functionsI won’t go details packages functionsI’ve relied excellent Max Kuhn’s Kjell Johnson’s book ‘Feature Engineering Selection: Practical Approach Predictive Models’ used code advanced feature exploration.’ve relied excellent Max Kuhn’s Kjell Johnson’s book ‘Feature Engineering Selection: Practical Approach Predictive Models’ used code advanced feature exploration.Without ado, let’s dive !","code":"#> Warning: The `path` argument of `write_lines()` is deprecated as of readr 1.4.0.\n#> ℹ Please use the `file` argument instead.\n#> This warning is displayed once every 8 hours.\n#> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated."},{"path":"chapter-2.html","id":"chapter-2","chapter":"2 Early data exploration","heading":"2 Early data exploration","text":"","code":""},{"path":"chapter-2.html","id":"overview-of-the-data","chapter":"2 Early data exploration","heading":"2.1 Overview of the data","text":"data already divided train test sets let’s load get sense train data looks like. ’ll leave test data (won’t even look ) end.Let’s first get sense train data.8693 observations 14 variables “Transported” response. specifics different variables explained detail competition website won’t repeat . ’s enough note mix categorical numerical variables response binary classification (True False).","code":"\ntrain <- read.csv(\"train.csv\", na.strings = \"\")\nstr(train)\n#> 'data.frame':    8693 obs. of  14 variables:\n#>  $ PassengerId : chr  \"0001_01\" \"0002_01\" \"0003_01\" \"0003_02\" ...\n#>  $ HomePlanet  : chr  \"Europa\" \"Earth\" \"Europa\" \"Europa\" ...\n#>  $ CryoSleep   : chr  \"False\" \"False\" \"False\" \"False\" ...\n#>  $ Cabin       : chr  \"B/0/P\" \"F/0/S\" \"A/0/S\" \"A/0/S\" ...\n#>  $ Destination : chr  \"TRAPPIST-1e\" \"TRAPPIST-1e\" \"TRAPPIST-1e\" \"TRAPPIST-1e\" ...\n#>  $ Age         : num  39 24 58 33 16 44 26 28 35 14 ...\n#>  $ VIP         : chr  \"False\" \"False\" \"True\" \"False\" ...\n#>  $ RoomService : num  0 109 43 0 303 0 42 0 0 0 ...\n#>  $ FoodCourt   : num  0 9 3576 1283 70 ...\n#>  $ ShoppingMall: num  0 25 0 371 151 0 3 0 17 0 ...\n#>  $ Spa         : num  0 549 6715 3329 565 ...\n#>  $ VRDeck      : num  0 44 49 193 2 0 0 NA 0 0 ...\n#>  $ Name        : chr  \"Maham Ofracculy\" \"Juanna Vines\" \"Altark Susent\" \"Solam Susent\" ...\n#>  $ Transported : chr  \"False\" \"True\" \"False\" \"False\" ..."},{"path":"chapter-2.html","id":"do-some-variables-have-zero-or-near-zero-variance","chapter":"2 Early data exploration","heading":"2.2 Do some variables have zero or near-zero variance?","text":"One first things might useful check whether variables zero near-zero variance. zero variance variable one rows value (imagine variable rows just number 1). variables useful prediction since don’t change way response.close cousin near-zero variances high percentage rows value don’t. can particularly problematic want repeated cross validation divide data subdata test models. subdata might zero variance others might get high variance variable.VIP variable near-zero variation (2.3% rows). ’ll see becomes issue later process.","code":"\nnearZeroVar(train, saveMetrics = TRUE) %>% rownames_to_column() %>% filter(nzv)\n#>   rowname freqRatio percentUnique zeroVar  nzv\n#> 1     VIP  41.66332    0.02300702   FALSE TRUE"},{"path":"chapter-2.html","id":"frequency-distribution-of-all-variables","chapter":"2 Early data exploration","heading":"2.3 Frequency distribution of all variables","text":"Let’s see values different variables distributed.\nFigure 2.1: Distribution response\nresponse training set balanced good means don’t need - oversampling balance . balanced response necessary tuning many models since makes metrics tune make sense. great unbalance true responses vs false ones, metrics like accuracy might distorted since even random guesses might give us high accuracy just fact distirbution unbalanced.\nFigure 2.2: Distribution predictor variables\nnumeric variables right-skewed, means outliers right horizontal axis amenities (RoomService, FoodCourt etc) high proportion zero values. difference scales also large. need apply kind preproces scale help models like K-nearest-neighbors (KNN). might also need add binary features (yes/1/0) amenities zero perhaps help models differentiate rest.Cabin Name variables near uniform distribution implies either won’t much predictive power even reduce accuracy introducing unnecessary noise model. either derive features variables include models.","code":"\nsjPlot::plot_frq(train, Transported, type = \"histogram\")\nmy_frq <- sjPlot::plot_frq(train, type = \"histogram\")\n\nsave_plot <- function(p, i) {\n  ggsave(filename = paste0(\"Variable\", i, \".png\"), plot = p, path = \"Extra/\")\n}\n\n# plotsToSVG <- walk2(.x = my_frq, .y = seq_along(my_frq), .f = save_plot)\nplotsToSVG <- map(1:length(my_frq), .f = \\(i) paste0(\"Extra/Variable\", i, \".png\"))\nslickR::slickR(plotsToSVG, height = \"480px\", width = \"672px\") +\n  slickR::settings(slidesToShow = 1, dots = TRUE)"},{"path":"chapter-2.html","id":"correlation-between-the-variables","chapter":"2 Early data exploration","heading":"2.4 Correlation between the variables","text":"\nFigure 2.3: Correlation numerical predictor variables\nsee ’s relatively high correlation home planets destinations well moderate correlation CryoSleep Transported already gives us hint CryoSleep might important. Otherwise, variables seem relatively uncorrelated good thing since models handle variables correlated.","code":"\ntrain %>%\n  na.omit(.) %>%\nDataExplorer::plot_correlation(., type = \"all\", theme_config = list(axis.text.x = element_text(angle = 90)))"},{"path":"chapter-2.html","id":"overview-of-missing-values","chapter":"2 Early data exploration","heading":"2.5 Overview of missing values","text":"\nFigure 2.4: Missing values overview\npredictor variables around 2% missing data relatively low. cluster missing values, can also see don’t overlap suggests ’re missing random due specific pattern. tells us can probably find suitable algorithm help us impute missing values based non-missing values. pattern clusters missing data, ’d explore uncover reasons non-random missingness.However, see exploration data might pattern missingness, least values missing can inferred others.","code":"\nplot_na_hclust(train)"},{"path":"chapter-3.html","id":"chapter-3","chapter":"3 Handle missing data","heading":"3 Handle missing data","text":"best way handle missing data first visualize get sense ’s going .","code":""},{"path":"chapter-3.html","id":"simple-but-useful-features","chapter":"3 Handle missing data","heading":"3.1 Simple but useful features","text":"’re given several useful bits information data competition website can apply create useful features. features, mean new variables derived existing ones. example, Cabin comprised information cabin number, deck side PassengerId contains passenger group id.’ve created function derives new variables existing ones. also creates features count number unique categories different variables passenger group. Since passenger group variable one missing values, makes sense start exploration others based . Questions ask : ‘passenger group travelling different home planets?’","code":"\nuseful_features <- function(x) {\n  x2 <- x %>%\n    mutate(PassengerGroup = str_split_i(PassengerId, \"_\", 1),\n           LastName = word(Name, -1),\n           Deck = str_split_i(Cabin, \"/\", 1),\n           CabinNumber = str_split_i(Cabin, \"/\", 2),\n           Side = str_split_i(Cabin, \"/\", 3),\n           TotalSpent = RoomService + FoodCourt + ShoppingMall + Spa + VRDeck,\n           PassengerCount = 1) %>% # I added this to use as a count variable in visualizations\n    group_by(PassengerGroup) %>%\n    add_count(PassengerGroup, name = \"PassengerGroupSize\") %>%\n    mutate(HomePlanetsPerGroup = n_distinct(HomePlanet, na.rm = TRUE),\n           DestinationsPerGroup = n_distinct(Destination, na.rm = TRUE),\n           CabinsPerGroup = n_distinct(Cabin, na.rm = TRUE),\n           TotalSpentPerGroup = sum(TotalSpent, na.rm = TRUE),\n           CryoSleepsPerGroup = n_distinct(CryoSleep, na.rm = TRUE),\n           VIPsPerGroup = n_distinct(VIP, na.rm = TRUE),\n           LastNamesPerGroup = n_distinct(LastName, na.rm = TRUE)) %>%\n    ungroup() %>%\n    mutate(across(.cols = c(HomePlanet, CryoSleep, Destination, VIP, Transported, Deck, Side, HomePlanetsPerGroup,\n                            PassengerGroupSize, DestinationsPerGroup, CabinsPerGroup, CryoSleepsPerGroup, VIPsPerGroup,\n                            LastNamesPerGroup, PassengerId),\n                  .fns = as.factor)) %>%\n    mutate(across(.cols = c(CabinNumber, Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, PassengerGroup),\n                  .fns = as.integer))\n  return(x2)\n}\n\ntrain2 <- useful_features(train)"},{"path":"chapter-3.html","id":"closer-look-at-missing-values","chapter":"3 Handle missing data","heading":"3.2 Closer look at missing values","text":"closer look variable missing values gives us insights. example, every passenger group always starts home planet. Figure 3.1 shows sample passenger groups home planets. one patterns missingness alluded earlier can use information replace missing HomePlanet values passengers belonging group known home planet. leave us passengers travelling alone.\nFigure 3.1: Sample missing values HomePlanet\ncan also see groups two travelers never housed cabins (non-solo) groups. words, group two passengers can spread across several cabins never share cabins groups two passengers. Figure 3.2 shows sample. can use information replace missing cabin values.\nFigure 3.2: Sample missing values Cabin\nlook new feature Deck, can see decks seem dedicated passengers specific home planet, see Figure 3.4. helps us replace even missing values HomePlanet.\nFigure 3.3: Relationsship Cabin passenger group.\nsee relationship CabinNumber PassengerGroup linear can use replace CabinNumber Deck known.\nFigure 3.4: Missing values Deck\nalso see aren’t VIPs travelling Earth can use information replace missing VIP-values home planet known.\nFigure 3.5: Missing values VIP\nalso told passengers cryosleep confined cabins must assume means spend credits amenities. words, can replace missing amenities zeroes passengers cryo sleep. reverse also true: passenger spent credits, passenger cryo sleep.One last insight can get missing data passengers 12 years age don’t spend credits. can therefore use replace even missing values amenities.\nFigure 3.6: Missing values ameneties\n","code":"\ntrain2 %>%\n  group_by(PassengerGroup) %>%\n  filter(any(is.na(HomePlanet))) %>%\n  ungroup() %>%\n  slice_sample(n = 50) %>%\n  ggplot(., mapping = aes(x = PassengerGroup, y = PassengerCount, fill = HomePlanet)) +\n    geom_col()  +\n    labs(title = \"Example missing HomePlanet\", x = \"Passenger group\", y = \"Number of passengers\") +\n    scale_y_continuous(breaks = seq(0, 9000, 50)) +\n    theme(axis.text.x = element_text(angle = 90, hjust = 1))\ntrain2 %>%\n  filter(PassengerGroupSize != 1 & Side == \"S\" & Deck == \"G\") %>%\n  slice_sample(n = 50) %>%\n  ggplot(., mapping = aes(x = as.factor(CabinNumber), y = PassengerCount, fill = PassengerGroup)) +\n  geom_col() +\n  labs(title = \"Example missing CabinNumber\", x = \"Cabin number\", y = \"Number of passengers\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = \"none\")\ntrain2 %>%\n  ggplot(., mapping = aes(x = CabinNumber, y = as.integer(PassengerGroup), colour = Deck)) +\n  geom_point() +\n  labs(title = \"CabinNumber against PassengerGroup\", x = \"Cabin number\", y = \"PassengerGroup\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\ntrain2 %>%\n  group_by(Deck) %>%\n  filter(any(is.na(HomePlanet))) %>%\n  ungroup() %>%\n  ggplot(., mapping = aes(x = Deck, y = PassengerCount, fill = HomePlanet)) +\n  geom_col() +\n  labs(title = \"Missing HomePlanet by Deck\", x = \"Deck\", y = \"Number of passengers\") +\n  scale_y_continuous(breaks = seq(0, 9000, 200)) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\ntrain2 %>%\n  ggplot(., mapping = aes(x = HomePlanet, y = PassengerCount, fill = VIP)) +\n  geom_col() +\n  labs(title = \"Missing VIP by HomePlanet\", x = \"HomePlanet\", y = \"Number of passengers\") +\n  scale_y_continuous(breaks = seq(0, 9000, 200)) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\ntrain2 %>%\n  ggplot(., mapping = aes(x = Age, y = TotalSpent)) +\n  geom_col() +\n  labs(title = \"Missing Age\", x = \"Age of passengers\", y = \"TotalSpent\") +\n  scale_y_continuous(breaks = seq(0, 500000, 50000)) +\n  scale_x_continuous(breaks = seq(0, 100, 2)) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))"},{"path":"chapter-3.html","id":"replace-data-with-manual-rules","chapter":"3 Handle missing data","heading":"3.3 Replace data with manual rules","text":"’ve summed replacement rules function .\nFigure 3.7: Missing values manual replacement.\nsee ’ve managed halv amount missing values many variables manual replacements. rest can handle imputation.","code":"\nmy_na_replace <- function(d) {\n  cabin_coef <- d %>%\n  nest(.by = Deck) %>%\n  filter(!is.na(Deck)) %>%\n  mutate(cabin_lm = map(.x = data, .f = \\(df) lm(CabinNumber ~ PassengerGroup, data = df, na.action = na.exclude)),\n         my_tidy = map(.x = cabin_lm, .f = \\(m) tidy(m))) %>%\n  select(Deck, my_tidy) %>%\n  unnest(my_tidy) %>%\n  select(Deck, term, estimate) %>%\n  pivot_wider(names_from = term, values_from = estimate) %>%\n  rename(Intercept = `(Intercept)`, Slope = PassengerGroup)\n  \n  d2 <- d %>%\n    # Replace HomePlanet for passengers in groups where the homeplanet is known from the other passengers\n    group_by(PassengerGroup) %>% \n    fill(HomePlanet, .direction = \"downup\") %>% \n    \n    # Replace Cabin by group cabin for groups with group count > 1. Update the Deck, CabinNumber and Side variables.\n    mutate(Cabin2 = Cabin) %>%\n    fill(data = ., Cabin2, .direction = \"downup\") %>%\n    ungroup() %>%\n    mutate(Cabin = if_else(is.na(Cabin) & PassengerGroupSize != 1, Cabin2, Cabin),\n           Deck = str_split_i(Cabin, \"/\", 1),\n           CabinNumber = as.integer(str_split_i(Cabin, \"/\", 2)),\n           Side = str_split_i(Cabin, \"/\", 3)) %>%\n    select(-Cabin2) %>%\n    \n    # Replace remaining CabinNumber with linear relationship with group\n    left_join(., cabin_coef, by = \"Deck\") %>%\n    mutate(CabinNumber = if_else(is.na(CabinNumber), Intercept + Slope * PassengerGroup, CabinNumber)) %>%\n    select(-Intercept, -Slope) %>%\n    \n    # Replace HomePlanet if the passenger is housed on a dedicated Deck\n    mutate(HomePlanet = if_else(is.na(HomePlanet) & Deck == \"G\", \"Earth\", HomePlanet),\n           HomePlanet = if_else(is.na(HomePlanet) & Deck %in% c(\"A\", \"B\", \"C\"), \"Europa\", HomePlanet)) %>%\n    \n    # Replace all of VIPs from Earth to FALSE\n    mutate(VIP = if_else(is.na(VIP) & HomePlanet == \"Earth\", \"False\", VIP)) %>%\n    \n    # Replace amenities with zero if CryoSleep is TRUE or if Age <= 12\n    # Replace CryoSleep with FALSE if the passenger has spent credits\n    mutate(across(.cols = c(RoomService, FoodCourt, ShoppingMall, Spa, VRDeck), \n                  .fns = ~ if_else(condition = CryoSleep == \"True\" | Age <= 12, true = 0, false = .x, missing = .x)),\n           CryoSleep = if_else(TotalSpent > 0 & is.na(CryoSleep), \"False\", CryoSleep))\n  return(d2)\n}\n\ntrain3 <- my_na_replace(train2)\ntrain3 <- useful_features(train3)\n\nplot_na_hclust(train3)"},{"path":"chapter-3.html","id":"replace-data-with-imputation","chapter":"3 Handle missing data","heading":"3.4 Replace data with imputation","text":"algorithms require missing data since find patterns missing data, can use imputation algorithms rest. ’ve used two: MissRanger KNN. Since KNN can sensitive scale data outliers, ’ve normalized numeric data avoid possible issues imputation.Note ’ve saved results imputations since can take time run.\n### MissRanger - Chained Random ForestsThe missRanger algorithm can impute variables time option select id variable included data used imputation. Note excluded Name variables improve computation time.","code":"\nrev_normalization <- function(v, rec) { # Custom function that will \"unnormalise\" numeric values inside mutate(across())\n  tidy_rec <- tidy(rec, number = 1)\n  v2 <- v * filter(tidy_rec, terms == cur_column() & statistic == \"sd\")$value + \n    filter(tidy_rec, terms == cur_column() & statistic == \"mean\")$value\n  v3 <- round(v2, 0)\n  return(v3)\n}\n\n# ranger_norm <- recipe(Transported ~ ., data = train3) %>%\n#   step_normalize(all_numeric_predictors()) %>%\n#   prep()\n# \n# train3_ranger <- ranger_norm %>%\n#   bake(new_data = NULL) %>%\n#   select(-c(Cabin, Name, LastName, PassengerCount))\n# \n# ranger <- missRanger(train3_ranger, formula = . ~ . -PassengerId, seed = 8584, verbose = 0)\n# \n# ranger_unnorm <- ranger %>%\n#   mutate(across(.cols = c(Age, CabinNumber, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck),\n#                 .fns = ~ rev_normalization(.x, ranger_norm)))\n# \n# ranger2 <- train3 %>%\n#   select(PassengerId, Cabin, Name, LastName, PassengerCount) %>%\n#   left_join(ranger_unnorm, ., by = \"PassengerId\")\n# \n# save(ranger2, file = \"Extra/MissRanger.RData\")\nload(\"Extra/MissRanger.RData\")"},{"path":"chapter-3.html","id":"knn---k-nearest-neighbors","chapter":"3 Handle missing data","heading":"3.4.1 KNN - K-Nearest Neighbors","text":"use recipe-package set process imputation step_impute_knn-function allows specify variables used imputation imputed.KNN-algorithm fast can impute multiple variables time. can also relatively easily tuned changing number neighbors imputation based although ’ve used default = 5.","code":"\ntrain3_for_knn <- train3 %>%\n  mutate(across(.cols = where(is.factor), .fns = as.character))\n\nvars_to_impute <- c(\"HomePlanet\", \"CryoSleep\", \"Destination\", \"Age\", \"VIP\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\",\n                    \"Spa\", \"VRDeck\", \"Deck\", \"Side\", \"CabinNumber\", \"LastName\")\nvars_for_imputing <- c(\"HomePlanet\", \"CryoSleep\", \"Destination\", \"Age\", \"VIP\", \"RoomService\", \"FoodCourt\",\n                              \"ShoppingMall\", \"Spa\", \"VRDeck\", \"PassengerGroup\", \"Deck\", \"Side\", \"CabinNumber\",\n                              \"PassengerGroupSize\", \"DestinationsPerGroup\", \"CabinsPerGroup\",\n                              \"CryoSleepsPerGroup\", \"VIPsPerGroup\", \"LastNamesPerGroup\")\n\ntrain3_noNA <- train3_for_knn[complete.cases(train3_for_knn),]\n  \nknn_impute_rec <- recipe(Transported ~ ., data = train3_noNA) %>%\n  step_normalize(Age, CabinNumber, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck) %>%\n  step_impute_knn(recipe = ., all_of(vars_to_impute), impute_with = imp_vars(all_of(vars_for_imputing)), neighbors = 5) \n\nset.seed(8584)\nknn_impute_prep <- knn_impute_rec %>% prep(strings_as_factors = FALSE)\n\nset.seed(8584)\nknn_impute_bake <- bake(knn_impute_prep, new_data = train3_for_knn)\n\nknn_impute_res <- knn_impute_bake %>%\n  mutate(across(.cols = c(Age, CabinNumber, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck),\n                .fns = ~ rev_normalization(.x, knn_impute_prep)))"},{"path":"chapter-3.html","id":"comparison-of-imputation-algorithms---numerical-variables","chapter":"3 Handle missing data","heading":"3.4.2 Comparison of imputation algorithms - numerical variables","text":"use skimr-package set metrics evaluate data wrangling imputated variables can compared non-imputed ones.\nFigure 3.8: Comparisson standard deviation numerical values imputation\nstandard deviation numeric variables isn’t affected imputation, although expected since 1% missing data. true mean, can seen Figure 3.9.\nFigure 3.9: Comparisson mean numerical values imputation\n","code":"\nmy_skim <- skimr::skim_with(numeric = skimr::sfl(min = ~min(., na.rm = TRUE), median = ~median(., na.rm = TRUE), \n                                   mean = ~mean(., na.rm = TRUE), max = ~max(., na.rm = TRUE), \n                                   sd = ~sd(., na.rm = TRUE)), append = FALSE)\n\nno_imp_skim <- train3 %>%\n  select(Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, CabinNumber) %>%\n  my_skim(.)\n\nranger_skim <- ranger2 %>%\n  select(Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, CabinNumber) %>%\n  my_skim(.)\n\nknn_skim <- knn_impute_res %>%\n  select(Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, CabinNumber) %>%\n  my_skim(.)\n\nsd_skim <- bind_cols(\"Variable\" = no_imp_skim$skim_variable, \"No imp\" = no_imp_skim$numeric.sd, \n                     \"MissRanger\" = ranger_skim$numeric.sd,  \"KNN\" = knn_skim$numeric.sd) %>%\n  pivot_longer(., cols = !Variable, names_to = \"Metric\", values_to = \"Standard_deviation\")\n\nmean_skim <- bind_cols(\"Variable\" = no_imp_skim$skim_variable, \"No imp\" = no_imp_skim$numeric.mean, \n                     \"missRanger\" = ranger_skim$numeric.mean, \"KNN\" = knn_skim$numeric.mean) %>%\n  pivot_longer(., cols = !Variable, names_to = \"Metric\", values_to = \"Mean\")\n\nsd_skim %>%\n  filter(Metric != \"No imp\") %>%\n  ggplot(., mapping = aes(x = Metric, y = Standard_deviation)) +\n  geom_point() +\n  geom_hline(data = sd_skim %>% filter(Metric == \"No imp\"), aes(yintercept = Standard_deviation, colour = \"orange\")) +\n  lims(y = c(0, NA)) +\n  facet_wrap(~Variable, scales = \"free\") +\n  scale_colour_discrete(name = \"Non-imputed\", labels = \"sd\", type = \"orange\")\nmean_skim %>%\n  filter(Metric != \"No imp\") %>%\n  ggplot(., mapping = aes(x = Metric, y = Mean)) +\n  facet_wrap(~Variable, scales = \"free\") +\n  geom_point() +\n  geom_hline(data = mean_skim %>% filter(Metric == \"No imp\"), aes(yintercept = Mean, colour = \"green\")) +\n  lims(y = c(0, NA)) +\n  scale_colour_discrete(name = \"Non-imputed\", labels = \"mean\", type = \"green\")"},{"path":"chapter-3.html","id":"comparison-of-imputation-algorithms---categorical-variables","chapter":"3 Handle missing data","heading":"3.4.3 Comparison of imputation algorithms - categorical variables","text":"comparison proportions categorical variables also shows imputation seems reasonable hasn’t introduced strange values like outliers. two sample comparisons HomePlanet CryoSleep encourage (follow along code) explore categorical variable seperately.\nFigure 3.10: Imputed distribution HomePlanet compared imputation\n\nFigure 3.11: Imputed distribution HomePlanet compared imputation\n","code":"\nmy_prop_plot <- function(df, v, t) {\n  g <- ggplot(data = df, mapping = aes(x = !!sym(t), fill = !!sym(v))) +\n    geom_bar() +\n    geom_text(aes(by = as.factor(!!sym(t))), stat = \"prop\", position = position_stack(vjust = 0.5)) +\n    labs(title = deparse(substitute(df)), x = t, y = \"Number of passengers\") +\n    scale_y_continuous(breaks = seq(0, 9000, 500)) +\n    theme(axis.text.x = element_text(angle = 90, hjust = 1))\n  return(g)\n}\n\nh1 <- my_prop_plot(train3, \"HomePlanet\", \"Transported\")\nh2 <- my_prop_plot(ranger2, \"HomePlanet\", \"Transported\")\nh3 <- my_prop_plot(knn_impute_res, \"HomePlanet\", \"Transported\")\n\n(h1 | h2 | h3) + plot_layout(guides = \"collect\", axis_titles = \"collect\")\nc1 <- my_prop_plot(train3, \"CryoSleep\", \"Transported\")\nc2 <- my_prop_plot(ranger2, \"CryoSleep\", \"Transported\")\nc3 <- my_prop_plot(knn_impute_res, \"CryoSleep\", \"Transported\")\n\n(c1 | c2 | c3) + plot_layout(guides = \"collect\", axis_titles = \"collect\")"},{"path":"chapter-3.html","id":"do-the-imputated-values-break-any-rules","chapter":"3 Handle missing data","heading":"3.4.4 Do the imputated values break any “rules”?","text":"One last thing must accept imputed values check whether imputation managed adhere ‘rules’ discovered earlier used manual replacement NA-values. use modified version useful_features-function update simple features.imputation didn’t seem break rule every passenger group travels planet, great.imputation didn’t break rule passengers <=12 years old don’t spend credits break rule passengers cryo sleep can’t spend credits.Another rule broken regards Deck variable passengers imputed housed decks despite travelling ‘wrong’ homeplanet deck. can deal general function checks ‘rules’ adjusts.\nFigure 3.12: Missing values overview imputation\nmissing values now variables won’t use modelling (’ll use features derived instead).","code":"\nuseful_features2 <- function(x) {\n  x2 <- x %>%\n    mutate(TotalSpent = RoomService + FoodCourt + ShoppingMall + Spa + VRDeck) %>%\n    group_by(PassengerGroup) %>%\n    add_count(PassengerGroup, name = \"PassengerGroupSize\") %>%\n    mutate(HomePlanetsPerGroup = n_distinct(HomePlanet, na.rm = TRUE),\n           DestinationsPerGroup = n_distinct(Destination, na.rm = TRUE),\n           CabinsPerGroup = n_distinct(Cabin, na.rm = TRUE),\n           TotalSpentPerGroup = sum(TotalSpent, na.rm = TRUE),\n           CryoSleepsPerGroup = n_distinct(CryoSleep, na.rm = TRUE),\n           VIPsPerGroup = n_distinct(VIP, na.rm = TRUE),\n           LastNamesPerGroup = n_distinct(LastName, na.rm = TRUE)) %>%\n    ungroup() %>%\n    mutate(across(.cols = c(HomePlanet, CryoSleep, Destination, VIP, Transported, Deck, Side, HomePlanetsPerGroup,\n                            PassengerGroupSize, DestinationsPerGroup, CabinsPerGroup, CryoSleepsPerGroup, VIPsPerGroup,\n                            LastNamesPerGroup, PassengerGroup, PassengerId),\n                  .fns = as.factor)) %>%\n    mutate(across(.cols = c(CabinNumber, Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck),\n                  .fns = as.integer))\n  return(x2)\n}\n\ncheck_knn <- useful_features2(knn_impute_res)\n\ncheck_knn %>%\n  filter(HomePlanetsPerGroup != 1) %>%\n  select(PassengerId, HomePlanet, HomePlanetsPerGroup)\n#> # A tibble: 0 × 3\n#> # ℹ 3 variables: PassengerId <fct>, HomePlanet <fct>,\n#> #   HomePlanetsPerGroup <fct>\ncheck_knn %>%\n  filter(Age <= 12 & TotalSpent > 0) %>%\n  select(PassengerId, CryoSleep, Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, TotalSpent)\n#> # A tibble: 0 × 9\n#> # ℹ 9 variables: PassengerId <fct>, CryoSleep <fct>,\n#> #   Age <int>, RoomService <int>, FoodCourt <int>,\n#> #   ShoppingMall <int>, Spa <int>, VRDeck <int>,\n#> #   TotalSpent <dbl>\n\ncheck_knn %>%\n  filter(CryoSleep == \"True\" & TotalSpent > 0) %>%\n  select(PassengerId, CryoSleep, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, TotalSpent)\n#> # A tibble: 5 × 8\n#>   PassengerId CryoSleep RoomService FoodCourt ShoppingMall\n#>   <fct>       <fct>           <int>     <int>        <int>\n#> 1 0115_01     True                0         0            0\n#> 2 2390_01     True                0         0            3\n#> 3 5157_01     True              814        12            2\n#> 4 7314_01     True                0         0            0\n#> 5 7512_01     True                5       598           18\n#> # ℹ 3 more variables: Spa <int>, VRDeck <int>,\n#> #   TotalSpent <dbl>\ncheck_knn %>%\n  filter(Deck %in% c(\"A\", \"B\", \"C\") & HomePlanet != \"Europa\" | Deck == \"G\" & HomePlanet != \"Earth\") %>%\n  select(PassengerId, HomePlanet, Deck)\n#> # A tibble: 23 × 3\n#>    PassengerId HomePlanet Deck \n#>    <fct>       <fct>      <fct>\n#>  1 0101_01     Mars       G    \n#>  2 0355_01     Earth      B    \n#>  3 0525_01     Earth      C    \n#>  4 0826_01     Earth      B    \n#>  5 0833_01     Europa     G    \n#>  6 0932_01     Mars       G    \n#>  7 1041_01     Europa     G    \n#>  8 1095_01     Europa     G    \n#>  9 1134_01     Europa     G    \n#> 10 1645_01     Europa     G    \n#> # ℹ 13 more rows\n\ncheck_knn %>%\n  filter(VIP == \"True\" & HomePlanet == \"Earth\") %>%\n  select(PassengerId, HomePlanet, VIP)\n#> # A tibble: 0 × 3\n#> # ℹ 3 variables: PassengerId <fct>, HomePlanet <fct>,\n#> #   VIP <fct>\nfix_knn <- function(df) {\n  amenities_summary <- df %>%\n    filter(Age > 12 & TotalSpent > 0) %>%\n    summarise(mean_age = round(mean(Age), 0), .by = c(CryoSleep, Deck))\n  \n  wrong_age <- df %>%\n    filter(Age <= 12 & TotalSpent > 0) %>%\n    left_join(., amenities_summary, by = c(\"CryoSleep\", \"Deck\")) %>%\n    select(PassengerId, mean_age)\n  \n  wrong_planet <- df %>%\n    filter(HomePlanetsPerGroup != 1) %>%\n    select(PassengerId, PassengerGroup, HomePlanet) %>%\n    group_by(PassengerGroup) %>%\n    mutate(HomePlanet_correct = first(HomePlanet)) %>%\n    ungroup() %>%\n    select(PassengerId, HomePlanet_correct)\n  \n  wrong_deck <- df %>%\n    filter(Deck %in% c(\"A\", \"B\", \"C\", \"G\")) %>%\n    mutate(Deck_correct = case_when(Deck %in% c(\"A\", \"B\", \"C\") & HomePlanet == \"Earth\" ~ \"G\",\n                                    Deck %in% c(\"A\", \"B\", \"C\") & HomePlanet == \"Mars\" ~ \"F\",\n                                    Deck == \"G\" & HomePlanet == \"Mars\" ~ \"F\",\n                                    Deck == \"G\" & HomePlanet == \"Europa\" ~ \"C\", .default = Deck)) %>%\n    select(PassengerId, Deck_correct)\n  \n  res <- df %>%\n  left_join(., wrong_age, by = \"PassengerId\") %>%\n  left_join(., wrong_planet, by = \"PassengerId\") %>%\n  left_join(., wrong_deck, by = \"PassengerId\") %>%\n  mutate(Age = if_else(Age <= 12 & TotalSpent > 0, mean_age, Age),\n         RoomService = if_else(CryoSleep == \"True\", 0, RoomService),\n         FoodCourt = if_else(CryoSleep == \"True\", 0, FoodCourt),\n         ShoppingMall = if_else(CryoSleep == \"True\", 0, ShoppingMall),\n         Spa = if_else(CryoSleep == \"True\", 0, Spa),\n         VRDeck = if_else(CryoSleep == \"True\", 0, VRDeck),\n         HomePlanet = if_else(HomePlanetsPerGroup != 1, HomePlanet_correct, HomePlanet),\n         Deck_correct = coalesce(Deck_correct, Deck),\n         Deck = Deck_correct) %>%\n  select(-mean_age, -HomePlanet_correct, -Deck_correct)\n  \n  return(res)\n}\n\nfixed_knn <- fix_knn(check_knn)\ntrain4 <- useful_features2(fixed_knn)\n\nplot_na_hclust(train4)"},{"path":"chapter-4.html","id":"chapter-4","chapter":"4 Exploration of categorical variables","heading":"4 Exploration of categorical variables","text":"","code":""},{"path":"chapter-4.html","id":"chi-squared-tests","chapter":"4 Exploration of categorical variables","heading":"4.1 Chi-squared tests","text":"traditional statistical test two categorical values chi^2 test, compares actual frequencies combination categorical variables perfectly independent frequency (frequency occur combination ratio overall ratio one variable). null hypothesis chi^2 test relationship variables.use set helper functions iterate different categorical variables summarize results tables.use typical 95% confidence interval cut-point comparison, can see three pairs variables p-values higher 5%, means variables independent . pairs involve Side feature perhaps suggests people VIP tickets cryo sleep weren’t clustered one side ship, well people travelling certain destination.simple comparison might suggest possible interactions effects variables consider. Let’s visualise variables related .","code":"\nmy_chisq_test <- function(var1, var2) { # Test and extract Chi^2 statistics\n  res <- rstatix::chisq_test(x = var1, y = var2)\n  ex_res <- c(chi = res$statistic, pval = res$p)\n  return(ex_res)\n}\n\nchi_sqr_res <- train4 %>%\n  select(HomePlanet, Destination, Deck, Side, CryoSleep, VIP, LastName) %>%\n  summarise(chi_stats = map(.x = across(everything()), .f = \\(x) map(.x = across(everything()), .f = \\(y) my_chisq_test(x, y))))\n\nchi_sqr_res2 <- chi_sqr_res %>%\n  unnest() %>%\n  unnest_wider(col = everything()) %>%\n  rename(chi_sqr = `chi.X-squared`, p_value = pval) %>%\n  bind_cols(expand.grid(Var1 = c(\"HomePlanet\", \"Destination\", \"Deck\", \"Side\", \"CryoSleep\", \"VIP\", \"LastName\"), \n                        Var2 = c(\"HomePlanet\", \"Destination\", \"Deck\", \"Side\", \"CryoSleep\", \"VIP\", \"LastName\")), .)\n\nchi_sqr_res2 %>%\n  select(Var1, Var2, chi_sqr, p_value) %>%\n  filter(p_value > 0.05 & Var1 != Var2) %>%\n  distinct(chi_sqr, .keep_all = TRUE) %>%\n  arrange(as.character(Var1), desc(p_value))\n#>        Var1        Var2   chi_sqr p_value\n#> 1 CryoSleep        Side 3.7837832  0.0518\n#> 2      Side Destination 1.5379546  0.4630\n#> 3       VIP        Side 0.5181925  0.4720"},{"path":"chapter-4.html","id":"mosaic-plots","chapter":"4 Exploration of categorical variables","heading":"4.2 Mosaic plots","text":"use custom function Kuhn’s Johnsson’s code improve default mosaic plot plot categorical variables help contigency tables pair. ’ve left LastName since many levels.\nFigure 4.1: Mosaic plots visualize relationships categorical variables\nmosaic plot can read horisontally can see height bars changes different (vertical) values variable. example, see share passengers cryosleep changes deck know Chi^2 test change significant.can return visual understanding relationship categorical variables whenever want check relationship metric makes sense. example, can see differences Side variables didn’t fall outside 5% p-value, like HomePlanet, seem relatively small.","code":"\nmy_mosaic <- function(dtab, i) {\n  png(filename = paste0(\"Extra/Mosaic\", i, \".png\"))\n  vcd::mosaic(dtab, pop = FALSE, highlighting = TRUE, highlighting_fill = colorspace::rainbow_hcl,\n            margins = unit(c(6, 1, 1, 8), \"lines\"),\n            labeling = vcd::labeling_border(rot_labels = c(90, 0, 0, 0), just_labels = c(\"left\", \"right\", \"center\", \"right\"),\n                                       offset_varnames = unit(c(3, 1, 1, 4), \"lines\")), keep_aspect_ratio = FALSE)\n  dev.off()\n}\n\nmy_tables <- list(\n  base::table(HomePlanet = train4$HomePlanet, Destination = train4$Destination),\n  base::table(HomePlanet = train4$HomePlanet, CryoSleep = train4$CryoSleep),\n  base::table(HomePlanet = train4$HomePlanet, Deck = train4$Deck),\n  base::table(HomePlanet = train4$HomePlanet, Side = train4$Side),\n  base::table(HomePlanet = train4$HomePlanet, VIP = train4$VIP),\n  \n  base::table(Destination = train4$Destination, CryoSleep = train4$CryoSleep),\n  base::table(Destination = train4$Destination, Deck = train4$Deck),\n  base::table(Destination = train4$Destination, Side = train4$Side),\n  base::table(Destination = train4$Destination, VIP = train4$VIP),\n  \n  base::table(CryoSleep = train4$CryoSleep, Deck = train4$Deck),\n  base::table(CryoSleep = train4$CryoSleep, Side = train4$Side),\n  base::table(CryoSleep = train4$CryoSleep, VIP = train4$VIP),\n  \n  base::table(Deck = train4$Deck, Side = train4$Side),\n  base::table(Deck = train4$Deck, VIP = train4$VIP),\n  \n  base::table(Side = train4$Side, VIP = train4$VIP)\n)\n\n# mosaic_plots <- map2(.x = my_tables, .y = 1:length(my_tables), .f = \\(t, it) my_mosaic(dtab = t, i = it))\n# mosaic_slick <- map(1:length(mosaic_plots), .f = \\(i) paste0(\"Extra/Mosaic\", i, \".png\"))\n# save(mosaic_slick, file = \"Extra/Mosaic slick plots.RData\")\n\nload(\"Extra/Mosaic slick plots.RData\")\nslickR::slickR(mosaic_slick, height = \"480px\", width = \"672px\") +\n  slickR::settings(slidesToShow = 1, dots = TRUE)"},{"path":"chapter-4.html","id":"correspondence-analysis","chapter":"4 Exploration of categorical variables","heading":"4.3 Correspondence Analysis","text":"Correspondence analysis uses residuals contingency table two variables compared frequency table variables ’ve unrelated . Figure 4.2 shows correspondence analysis Destination Deck.\nFigure 4.2: Correspondance analysis Destination Deck variables.\nway read plot follows:horizontal vertical components show amount Chi^2 statistic respective component accounts . Another way think amount information original variables explained either horizontal vertical direction. eigenvalues inside parenthesis gives us sense component important. example, horizontal axis much important cases.horizontal vertical components show amount Chi^2 statistic respective component accounts . Another way think amount information original variables explained either horizontal vertical direction. eigenvalues inside parenthesis gives us sense component important. example, horizontal axis much important cases.distance origin either direction tells us rare particular category . example, Deck T five passengers ’s rare.distance origin either direction tells us rare particular category . example, Deck T five passengers ’s rare.Categories variable close together (particularly along horizontal axis case) suggest similarities categories. example, decks -C seem similar variation.Categories variable close together (particularly along horizontal axis case) suggest similarities categories. example, decks -C seem similar variation.Categories different variables close together suggest dependence especially distance origin large. trick see strength relationship imagine straight line one category orgin category. greater distance smaller angle, stronger relationship. example, draw line deck origin Cancri, get relatively long line tiny angle.Categories different variables close together suggest dependence especially distance origin large. trick see strength relationship imagine straight line one category orgin category. greater distance smaller angle, stronger relationship. example, draw line deck origin Cancri, get relatively long line tiny angle.can check insights make sense mosaic plot . example, decks -C seem unusually high proportion passengers travel Cancri decks D-G seem common travellers Trappist although relationship moderate.\nFigure 4.3: Correspondance analysis HomePlanet Deck variables.\nHomePlanet Deck, see strong relationship Europa decks -C well Earth deck G. might make sense create feature decks -C pooled single category potentially reduce noise data.","code":"\nplot(FactoMineR::CA(base::table(Deck = train4$Deck, Destination = train4$Destination), graph = FALSE), \n     title = \"Destination and Deck\")\nplot(FactoMineR::CA(base::table(Deck = train4$Deck, HomePlanet = train4$HomePlanet), graph = FALSE), \n     title = \"HomePlanet and Deck\")"},{"path":"chapter-4.html","id":"relationships-between-categorical-variables-and-the-outcome","chapter":"4 Exploration of categorical variables","heading":"4.4 Relationships between categorical variables and the outcome","text":"far, ’ve looked relationships categorical predictors related response. can explore binomial proportion test (code heavily borrowed Kuhn Johnson). sense similar chi^2 test compares actual proportions within group given expected proportion, case proportion transported total number passengers.\nFigure 4.4: categorical variables plotted binomial plots confidence intervals. red dotted line shows average probability response across entire training set.\nsee lot interesting details let us focus features relate passenger group.\nFigure 4.5: PassengerGroupSize plotted binomial plot confidence intervals. red dotted line shows average probability response across entire training set.\nFigure 4.5 suggests might difference passengers travel alone don’t. Perhaps binary feature tracks whether passenger travels solo within group benefit. Also, perhaps large groups less likely transported, although don’t much data .\nFigure 4.6: DestinationsPerGroup plotted binomial plot confidence intervals. red dotted line shows average probability response across entire training set.\nFigure 4.6 suggests might slight difference groups passengers travelled destination didn’t. differences small, presence feature might improve models.Let’s create function add new features ’ve discovered data.Let’s explore VIP variables bit . Figure 4.7 suggests chances transported higher passengers group another passenger VIP ticket time VIP ticket seems reduce chance transported.\nFigure 4.7: closer look VIP variable relation response.\nBased can see Figure 4.8, passengers groups one passenger VIP-ticket likely transported. can related fact VIP-passengers spend amenities , turn, might increase chances transported.explore effects numerical variables next chapter.\nFigure 4.8: closer look VIP VIPsPerGroup response.\n","code":"\nresponse_rate = mean(train4$Transported == \"True\")\n\nmy_binom <- function(df, t) { # Test whether the differences in proportions (of transported) are significant\n  p <- infer::prop_test(x = df, response = !!sym(t))\n  df2 <- df %>%\n    mutate(Lower = p$lower_ci, \n           Upper = p$upper_ci,\n           Proportion = sum(!!sym(t) == \"True\") / length(!!sym(t)))\n  return(df2)\n}\n\nmy_binom_plot <- function(df, v, t) { # Applies the proportion test to different categories of a variable and plots the results\n  p <- df %>%\n    group_split(!!sym(v)) %>%\n    map(.x = ., .f = \\(df) my_binom(df, t)) %>%\n    bind_rows() %>%\n    mutate(my_var = reorder(!!sym(v), Proportion)) %>%\n    ggplot(., aes(x = my_var, y = Proportion)) +\n    geom_errorbar(aes(ymin = 1 - Lower, ymax = 1 - Upper), width = .1) +\n    geom_point() +\n    geom_hline(yintercept = response_rate, col = \"red\", alpha = .8, lty = 4) + \n    scale_y_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1)) +\n    labs(x = \"\", title = v)\n  \n  return(p)\n}\nsave_plot <- function(p, i) {\n  ggsave(filename = paste0(\"Extra/Binomial\", i, \".png\"), plot = p)\n}\n\nbinom_plots <- train4 %>%\n  select(where(is.character), where(is.factor)) %>%\n  summarise(across(.cols = -c(Cabin, Name, LastName, PassengerId, Transported, PassengerGroup), .fns = list)) %>%\n  imap(.f = ~my_binom_plot(train4, .y, \"Transported\"))\n\n# binom_plots2 <- walk2(.x = binom_plots, .y = seq_along(binom_plots), .f = save_plot)\n# binom_slick <- map(1:length(binom_plots), .f = \\(i) paste0(\"Extra/Binomial\", i, \".png\"))\n# save(binom_slick, file = \"Extra/Biomial slick plots.RData\")\n\nload(\"Extra/Biomial slick plots.RData\")\nslickR::slickR(binom_slick, height = \"480px\", width = \"672px\") +\n  slickR::settings(slidesToShow = 1, dots = TRUE)\nmy_binom_plot(train4, \"PassengerGroupSize\", \"Transported\")\nmy_binom_plot(train4, \"DestinationsPerGroup\", \"Transported\")\nadd_grp_features <- function(df) {\n  res <- df %>%\n  mutate(Solo = if_else(PassengerGroupSize == 1, 1, 0),\n         LargeGroup = if_else(as.integer(PassengerGroupSize) > 7, 1, 0),\n         TravelTogether = if_else(DestinationsPerGroup == 1, 1, 0))\n}\n\ntrain5 <- add_grp_features(train4)\nv1 <- my_binom_plot(train5, \"VIP\", \"Transported\")\nv2 <- my_binom_plot(train5, \"VIPsPerGroup\", \"Transported\")\n\nv1 + v2 + plot_layout(axis_titles = \"collect_y\")\ng1 <- train5 %>%\n  select(VIP, Transported, VIPsPerGroup) %>%\n  filter(VIPsPerGroup == 2) %>%\n  ggplot(., mapping = aes(x = VIP, fill = Transported)) +\n  geom_bar() +\n  geom_text(aes(by = VIP), stat = \"prop\", position = position_stack(vjust = 0.5)) +\n  facet_wrap(~VIPsPerGroup, labeller = \"label_both\") +\n  labs(title = \"Two VIPsPerGroup\", x = \"VIP\", y = \"Number of passengers\") + \n  theme(axis.text.x = element_text(angle = 90, hjust = 1), text = element_text(size = 10), plot.title = element_text(size = 10))\n\ng2 <- train5 %>%\n  select(VIP, Transported) %>%\n  ggplot(., mapping = aes(x = VIP, fill = Transported)) +\n  geom_bar() +\n  geom_text(aes(by = VIP), stat = \"prop\", position = position_stack(vjust = 0.5)) +\n  labs(title = \"VIP share total\", x = \"VIP\", y = \"Number of passengers\") + \n  theme(axis.text.x = element_text(angle = 90, hjust = 1), text = element_text(size = 10), plot.title = element_text(size = 10))\n\n(g1 + g2) + \n  plot_layout(guides = \"collect\", axis_titles = \"collect\")"},{"path":"chapter-5.html","id":"chapter-5","chapter":"5 Exploration of numerical variables","heading":"5 Exploration of numerical variables","text":"now turn numerical variables see affect response.","code":""},{"path":"chapter-5.html","id":"name-variable","chapter":"5 Exploration of numerical variables","heading":"5.1 Name variable","text":"First, let’s transform name variable numerical values. can assume rank order names based fact variable distribution uniform (see Figure 2.1). use simple encoding convert names numbers.Let’s also explore count values names visually see look response.\nFigure 5.1: Exploration counts LastName variable LastNameCount number passengers total share last name LastNamesPerGroup number passengers share last name within group.\nseem difference good news since allows us get use name variable original form didn’t seem much variance. Hopefully features prove beneficial.","code":"\nencode_cat_to_numeric <- function(x) {\n  x <- factor(x, ordered = FALSE)\n  x <- unclass(x)\n  return(x)\n}\n\nadd_name_features <- function(df) {\n  res <- df %>%\n  mutate(LastNameAsNumber = encode_cat_to_numeric(LastName)) %>%\n  add_count(x = ., LastNameAsNumber, name = \"LastNameCount\") %>%\n  mutate(across(.cols = c(PassengerGroup, LastNameAsNumber), .fns = as.integer))\n}\n\ntrain6 <- add_name_features(train5)\ndf1 <- train6 %>%\n  select(Transported, LastNamesPerGroup) %>%\n  group_by(LastNamesPerGroup, Transported) %>%\n  summarise(count = n()) %>%\n  mutate(perc = count / sum(count))\n\ng1 <- ggplot(data = df1) +\n  geom_bar(aes(x = LastNamesPerGroup, y = perc*100, fill = Transported), stat = \"identity\") +\n  labs(y = \"Percent transported\")\n\ndf2 <- train6 %>%\n  select(Transported, LastNameCount) %>%\n  group_by(LastNameCount, Transported) %>%\n  summarise(count = n()) %>%\n  mutate(perc = count / sum(count))\n\ng2 <- ggplot(data = df2) +\n  geom_bar(aes(x = LastNameCount, y = perc*100, fill = Transported), stat = \"identity\") +\n  labs(y = \"Percent transported\")\n\ng1 + g2 + plot_layout(guides = \"collect\", axis_titles = \"collect_y\")"},{"path":"chapter-5.html","id":"age-cabinnumber-and-lastnames","chapter":"5 Exploration of numerical variables","heading":"5.2 Age, CabinNumber and LastNames","text":"Kuhn Johnson propose smoothing function using generalized additive models use penalized regression create smoothing numeric variables response. ’ve modified function somewhat.\nFigure 5.2: General additive model (GAM) plots Age smoothed confidence intervals. red dotted line shows average probability response across entire training set.\nPassengers younger 15 years age seem higher chance transported, effect significant younger passenger . rest passengers, age doesn’t seem matter much. remember passengers 12 years old younger never spent credits amenities real divide might number, rather 15. ’ll remember consider features might want create.\nFigure 5.3: General additive model (GAM) plots PassengerGroup smoothed confidence intervals. red dotted line shows average probability response across entire training set.\nPassenger groups seem effect ’s limited.\nFigure 5.4: General additive model (GAM) plots CabinNumber smoothed confidence intervals. red dotted line shows average probability response across entire training set.\nCabinNumber shows stronger effects passengergroup. look closer cabins around number 1000, see cabins decks F G. look back Figure 4.4 shows Deck response, can see decks show smaller chance transported. might suggest addition cabin number provide way models find subgroups different response compared average decks.\nFigure 5.5: General additive model (GAM) plots LastNameAsNumber smoothed confidence intervals. red dotted line shows average probability response across entire training set.\nPerhaps surprise LastName effect. Remember, however, counts last names saw Figure 5.1 might provide useful information.","code":"\nmy_smooth_plot <- function(d, v) {\n  TransportedRate <- mean(d$Transported == \"True\")\n  \n  my_df <- d %>% \n    select(!!sym(v), Transported) %>%\n    arrange(!!sym(v))\n  \n  my_df_small <- my_df %>%\n    distinct(!!sym(v))\n\n  gam_model <- mgcv::gam(as.formula(paste(\"Transported\", \"~ s(\", v, \")\")), data = my_df, family = binomial())\n \n  my_df_small <- my_df_small %>%\n    mutate(\n      link = predict(gam_model, my_df_small, type = \"link\"),\n      se = predict(gam_model, my_df_small, type = \"link\", se.fit = TRUE)$se.fit,\n      upper = link + qnorm(.975) * se,\n      lower = link - qnorm(.975) * se,\n      lower = binomial()$linkinv(lower),\n      upper = binomial()$linkinv(upper),\n      probability = binomial()$linkinv(link)\n    )\n  \n  g <- ggplot(my_df_small, aes(x = !!sym(v))) + \n        geom_line(aes(y = probability)) + \n        geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"grey\", alpha = .5) + \n        geom_hline(yintercept = TransportedRate, col = \"red\", alpha = .8, lty = 4)  + \n        scale_y_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1)) +\n        labs(x = v, title = paste(\"Smoothed\", v))\n\n  return(g)\n}\n\nmy_smooth_plot(train6, \"Age\")\nmy_smooth_plot(train6, \"PassengerGroup\")\nmy_smooth_plot(train6, \"CabinNumber\")\nmy_smooth_plot(train6, \"LastNameAsNumber\")"},{"path":"chapter-5.html","id":"amenities","chapter":"5 Exploration of numerical variables","heading":"5.3 Amenities","text":"amenity variables zero might reflect fact passenger cryosleep let’s filter plot .\nFigure 5.6: General additive model (GAM) plots RoomService, Spa VRDeck smoothed confidence intervals. red dotted line shows average probability response across entire training set.\nPassengers spent credits RoomService, Spa VRDeck seem less likely transported effects seem large.\nFigure 5.7: General additive model (GAM) plots FoodCourt ShoppingMall smoothed confidence intervals. red dotted line shows average probability response across entire training set.\nreverse true passengers spent credits FoodCourt ShoppingMall instead seem likely transported.\nFigure 5.8: General additive model (GAM) plots TotalSpent smoothed confidence intervals. red dotted line shows average probability response across entire training set.\nTotalSpent variable seems smooth effects individual amenities might reduce model performance. prepared remove models.summary, since amenity variables lot zero values even control CryoSleep, want create binary variables indicate zero value. binary variable zero amenities non-zero values therefore drop models use coefficients act like categorical variable value amenities zero.","code":"\ns1 <- my_smooth_plot(train6 %>% filter(CryoSleep == \"False\"), \"RoomService\")\ns2 <- my_smooth_plot(train6 %>% filter(CryoSleep == \"False\"), \"Spa\")\ns3 <- my_smooth_plot(train6 %>% filter(CryoSleep == \"False\"), \"VRDeck\")\n\ns1 + s2 + s3 + plot_layout(axis_titles = \"collect_y\")\ns4 <- my_smooth_plot(train6 %>% filter(CryoSleep == \"False\"), \"FoodCourt\")\ns5 <- my_smooth_plot(train6 %>% filter(CryoSleep == \"False\"), \"ShoppingMall\")\n\ns4 + s5 + plot_layout(axis_titles = \"collect_y\")\nmy_smooth_plot(train6 %>% filter(CryoSleep == \"False\"), \"TotalSpent\")\nbin_for_zero <- function(df) {\n  res <- df %>% mutate(ZeroRoomService = if_else(CryoSleep == \"False\" & RoomService == 0, 1, 0),\n                       ZeroFoodCourt = if_else(CryoSleep == \"False\" & FoodCourt == 0, 1, 0),\n                       ZeroShoppingMall = if_else(CryoSleep == \"False\" & ShoppingMall == 0, 1, 0),\n                       ZeroSpa = if_else(CryoSleep == \"False\" & Spa == 0, 1, 0),\n                       ZeroVRDeck = if_else(CryoSleep == \"False\" & VRDeck == 0, 1, 0))\n  return(res)\n}\n\ntrain6 <- bin_for_zero(train6)"},{"path":"chapter-5.html","id":"correlations","chapter":"5 Exploration of numerical variables","heading":"5.4 Correlations","text":"can see PassengerGroup CabinNumber highly correlated cause problems models sensitive correlated variables. consider using one variable see one gives better results.","code":"\ntrain6 %>%\n  select(Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, CabinNumber, LastNameAsNumber, PassengerGroup) %>%\n  DataExplorer::plot_correlation(., type = \"continuous\", theme_config = list(axis.text.x = element_text(angle = 90)))"},{"path":"chapter-6.html","id":"chapter-6","chapter":"6 Interactions","heading":"6 Interactions","text":"far ’ve created features single variables effects two variables together? help models added interaction effect example HomePlanet Destination create new feature HomeDestination? interactions?previous competition Titanic 1912, sex passenger mattered (women likely survive) ticket class mattered (first class likely survive) interaction “woman first class” almost 100% survival interaction improved model (remember correctly). want discover interactions exist variables space odyssey.course, won’t know extent improvement test interaction effects various models. models inherently discover interactions (like tree-models) addition interaction effects might matter might matter others.","code":""},{"path":"chapter-6.html","id":"visual-exploration-of-interactions","chapter":"6 Interactions","heading":"6.1 Visual exploration of interactions","text":"Since categorical variables, let’s visualize possible interactions. use default glm logistic regression model formula:\nTransported ~ (.)^2 amounts Outcome ~ Variable_1 + Variable_2 + Variable_1 x Variable_2\nFigure 6.1: Interaction effects pairs categorical variables response.\nParallel lines indicate significant interaction effects lines cross indicate potential significant interactions. ’ll highlight interactions .\nFigure 6.2: Interaction CryoSleep HomePlanet\ninteraction CryoSleep HomePlanet suggests passengers Earth less likely transported cryosleep suggests interaction CryoSleep & HomePlanet useful.\nFigure 6.3: Interaction Deck Side\ninteraction Deck Side, however, seems show minor effect, .Figures 6.4 6.5 show interaction affects numerical categorical variables.\nFigure 6.4: Interaction effects pairs variables response. Part 1.\n\nFigure 6.5: Interaction effects pairs variables response. Part 2.\nBased see figures, seem large interaction effects numerical variables, especially amenities. ’ll keep mind explore .","code":"\nplot_simple_int <- function(df, v1, v2) {\n  tmp_vars <- c(\"Transported\", v1, v2)\n  tmp_model <- glm(Transported ~ (.)^2, data = df[, tmp_vars], family = binomial())\n  p <- interactions::cat_plot(tmp_model, pred = {{ v1 }}, modx = {{ v2 }}, geom = \"line\", colors = c25,\n                       main.title = paste(v1, \"and\", v2)) +\n    theme(text = element_text(size = 40), plot.title = element_text(size = 40))\n  return(p)\n}\n\npreds_cat <- c(\"CryoSleep\", \"HomePlanet\", \"Destination\", \"VIP\", \"Deck\", \"Side\")\npairs_cat <- combn(preds_cat, 2, simplify = FALSE)\nc25 <- c(\"dodgerblue2\", \"#E31A1C\", \"green4\", \"#6A3D9A\", \"#FF7F00\", \"black\", \"gold1\", \"skyblue2\", \"#FB9A99\", \"palegreen2\", \"#CAB2D6\",\n  \"#FDBF6F\", \"gray70\", \"khaki2\", \"maroon\", \"orchid1\", \"deeppink1\", \"blue1\", \"steelblue4\", \"darkturquoise\", \"green1\", \"yellow4\",\n  \"yellow3\", \"darkorange4\", \"brown\") # Had to add extra colours because I couldn't get `cat_plot` to work with defaults\n\nsave_plot <- function(p, i) {\n  ggsave(filename = paste0(\"Extra/PairInt\", i, \".png\"), plot = p)\n}\n\n# cat_pair_int_plots <- pairs_cat %>%\n#   map(.x = ., .f = \\(vp) plot_simple_int(train6, vp[1], vp[2]))\n# \n# cat_plots <- walk2(.x = cat_pair_int_plots, .y = seq_along(cat_pair_int_plots), .f = save_plot)\n# cat_slick <- map(1:length(cat_pair_int_plots), .f = \\(i) paste0(\"Extra/PairInt\", i, \".png\"))\n# save(cat_slick, file = \"Extra/Plots cat.RData\")\nload(\"Extra/Plots cat.RData\")\n\nslickR::slickR(cat_slick, height = \"480px\", width = \"672px\") +\n  slickR::settings(slidesToShow = 1, dots = TRUE)\nplot_simple_int(train6, \"CryoSleep\", \"HomePlanet\")\nplot_simple_int(train6, \"Deck\", \"Side\")\nplot_simple_int2 <- function(df, v1, v2) {\n  tmp_vars <- c(\"Transported\", v1, v2)\n  tmp_model <- glm(Transported ~ (.)^2, data = df[, tmp_vars], family = binomial())\n  p <- interactions::interact_plot(tmp_model, pred = {{ v1 }}, modx = {{ v2 }}, geom = \"line\", colors = c25,\n                       main.title = paste(v1, \"and\", v2)) +\n    scale_x_log10() +\n    theme(text = element_text(size = 40), plot.title = element_text(size = 40))\n  return(p)\n}\n\npreds_num <- c(\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"CabinNumber\", \"LastNameAsNumber\",\n               \"PassengerGroup\", \"CryoSleep\", \"HomePlanet\", \"Destination\", \"VIP\", \"Deck\", \"Side\")\npairs_num <- combn(preds_num, 2, simplify = FALSE)\npairs_num <- pairs_num[1:90]\n\nsave_plot2 <- function(p, i) {\n  ggsave(filename = paste0(\"Extra/PairIntNum\", i, \".png\"), plot = p)\n}\n\n# num_pair_int_plots <- pairs_num %>%\n#   map(.x = ., .f = \\(vp) plot_simple_int2(train6, vp[1], vp[2]))\n# \n# int_plots_slick <- walk2(.x = num_pair_int_plots, .y = seq_along(num_pair_int_plots), .f = save_plot2)\n# int_plots_slick <- map(1:length(num_pair_int_plots), .f = \\(i) paste0(\"Extra/PairIntNum\", i, \".png\"))\n# save(int_plots_slick, file = \"Extra/Plots num.RData\")\nload(\"Extra/Plots num.RData\")\n\nslickR::slickR(int_plots_slick[1:45], height = \"480px\", width = \"672px\") +\n  slickR::settings(slidesToShow = 1, dots = TRUE)\nslickR::slickR(int_plots_slick[46:90], height = \"480px\", width = \"672px\") +\n  slickR::settings(slidesToShow = 1, dots = TRUE)"},{"path":"chapter-6.html","id":"interaction-significance-with-only-variable-pairs-and-their-interactions","chapter":"6 Interactions","heading":"6.2 Interaction significance with only variable pairs and their interactions","text":"One problem visual approach don’t know interaction effects real - sense represent true relationship outcome - ’re called false positives - , random effects happened present training data. example, fact passengers Earth seem less likely transported even cryo sleep reflect true aspect spacetime anomaly caused transportation another dimension pattern just something happened time pure chance? Another way think : Spaceship Titanic pass spacetime anomaly thousand times, pattern persist?explore , must validate effects cross validation. continue use simple glm model model response pair variables compare similar model includes interaction term ’ll use accuracy metric comparison.\nFigure 6.6: Accuracy GLM-models using pairs variables interactions.\nsee many variable pairs show significant improvement (based p-value < 5%), although improvements many cases relatively marginal. Furthermore, ’ve used cutoff 5% without adjustment can problematic since tests run 5% cutoff, higher chance finding interactions effect purely chance (fact, 105 pairs 5% cutoff, chances getting false positive practically guaranteed). look adjustment methods p-values take account later.now, can conclude variables CryoSleep & Deck, Deck & Spa, Deck & VRDeck high accuracy scores without interactions seem improved interactions. Let’s see effects persist expand exploration interactions.","code":"\ncompare_models_1way <- function(a, b, metric = a$metric[1], ...) { # A customized compare_models function from caret that allows for\n  mods <- list(a, b)                                               # a custom t.test adjustment in the diff-function\n  rs <- resamples(mods)\n  diffs <- diff(rs, metric = metric[1], adjustment = \"none\", ...)\n  res <- diffs$statistics[[1]][[1]]\n  return(res)\n}\n\npair_model <- function(df, v1, v2) { # Model without interactions with only two variables\n  tmp_vars <- c(\"Transported\", v1, v2)\n  set.seed(8584)\n  m <- train(Transported ~ ., data = df[, tmp_vars], preProc = NULL, method = \"glm\", metric = \"Accuracy\", trControl = ctrl)\n  return(m)\n}\n\npair_int_model <- function(df, v1, v2) { # Model with interactions with only two variables\n  tmp_vars <- c(\"Transported\", v1, v2)\n  set.seed(8584)\n  m <- train(Transported ~ (.)^2, data = df[, tmp_vars], preProc = NULL, method = \"glm\", metric = \"Accuracy\", trControl = ctrl)\n  return(m)\n}\n\npreds_cat <- c(\"CryoSleep\", \"HomePlanet\", \"Destination\", \"Age\", \"VIP\", \"Deck\", \"Side\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\",\n               \"Spa\", \"VRDeck\", \"CabinNumber\", \"LastNameAsNumber\", \"PassengerGroup\")\npairs <- combn(preds_cat, 2, simplify = FALSE)\npairs_cols <- combn(preds_cat, 2, simplify = TRUE) %>%\n  t() %>%\n  as.data.frame()\n\nctrl <- trainControl(method = \"repeatedcv\", repeats = 5, classProbs = TRUE, summaryFunction = multiClassSummary)\n\n# my_cluster <- makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# no_int_mods <- pairs %>%\n#   map(.x = ., .f = \\(vp) pair_model(train6, vp[1], vp[2]))\n# \n# int_mods <- pairs %>%\n#   map(.x = ., .f = \\(vp) pair_int_model(train6, vp[1], vp[2]))\n# \n# diff_res <- map2(.x = int_mods, .y = no_int_mods, .f = \\(m1, m2) compare_models_1way(m1, m2, metric = \"Accuracy\", \n#                                                                                      alternative = \"greater\"))\n# no_int_acc <- no_int_mods %>%\n#   map(.x = ., .f = \\(m) getTrainPerf(m)[1, \"TrainAccuracy\"]) %>%\n#   list_c(.)\n# \n# int_acc <- int_mods %>%\n#   map(.x = ., .f = \\(m) getTrainPerf(m)[1, \"TrainAccuracy\"]) %>%\n#   list_c(.)\n# \n# save(no_int_acc, file = \"Extra/No int acc.RData\")\n# save(int_acc, file = \"Extra/Int acc.RData\")\n# save(diff_res, file = \"Extra/Diff results pairs.RData\")\n# \n# stopCluster(my_cluster)\n# unregister()\n\nload(\"Extra/No int acc.RData\")\nload(\"Extra/Int acc.RData\")\nload(\"Extra/Diff results pairs.RData\")\n\ndiff_res2 <-\n  data.frame(Improvement = map_dbl(.x = diff_res, .f = \\(est) est$estimate),\n             Pvalue = map_dbl(.x = diff_res, .f = \\(p) p$p.value)) %>%\n  bind_cols(., No_Int_Accuracy = no_int_acc) %>%\n  bind_cols(., Int_Accuracy = int_acc) %>%\n  bind_cols(., pairs_cols)\ndiff_res2 %>% \n  filter(Pvalue <= 0.05) %>%\n  pivot_longer(cols = c(No_Int_Accuracy, Int_Accuracy)) %>%\n  mutate(Pairs = str_c(V1, \" and \", V2)) %>%\n  ggplot(., aes(x = reorder(Pairs, X = value), y = value, fill = name)) +\n  geom_col(position = position_dodge2()) +\n  coord_flip() +\n  labs(title = \"Significant pairwise interactions\", x = \"Variable pairs\", y = \"Accuracy\") +\n  scale_fill_discrete(name = \"Models\", labels = c(\"With interactions\", \"Without interactions\")) +\n  theme(legend.position = \"top\")"},{"path":"chapter-6.html","id":"interaction-significance-with-entire-model-and-pairwise-interactions","chapter":"6 Interactions","heading":"6.3 Interaction significance with entire model and pairwise interactions","text":"One weakness approach ’ve looked variable pairs interactions absence variables don’t know pairwise interactions contribute model variables. improvements still persist become correlated existing variables effects lessen even introduce noise data?Let’s explore .first look results ANOVA model comparison, see significant improvements model interactions pairs one without exist.Next, focus resampled performances, can see three interaction effects statistically significant without p-value adjustment.\nFigure 6.7: Accuracy GLM-models using pair-interactions together variables significant interaction effects without p-value adjustment.\nKuhn Johnson write ‘interactions discovered included broader model contains (perhaps correlated) predictors, importance model may diminished. (…) might reduce number predictors considered important (since residual degrees freedom smaller) discovered interactions likely reliably important larger model.’Let us therefore apply adjustments.\nFigure 6.8: Accuracy GLM-models using pair-interactions together variables significant interaction effects Bonferroni p-value adjustment.\nadjust values, single interaction effect remains: CryoSleep & HomePlanet. stricter adjustment Bonferroni multiplies p-values number tests (105 case) less strict adjustment Benjamini & Hochberg sorts p-values ascending order multiplies one total number tests divided p-value’s position (lowest value gets multiplied 105/1 case, second lowest 105/2 ).tell us? suggests interaction effects seem significant evaluated together entire dataset single interaction (CryoSleep & HomePlanet) likely truly relevant caused false positive effect many tests. already seen Figure 6.2 interaction CryoSleep & HomePlanet makes sense look two interactions without p-value adjustment Figure 6.1 (Deck & HomePlanet well Deck & Destination), see seem large interaction effects.Let’s add interaction effects far variable can use later.","code":"\nset.seed(8584)\nmy_split <- initial_split(train6, prop = 0.8)\nint_train <- training(my_split) %>%\n  mutate(across(.cols = c(PassengerGroup), .fns = as.integer)) %>%\n  select(CryoSleep, HomePlanet, Destination, VIP, Deck, Side, Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, CabinNumber,\n         LastNameAsNumber, PassengerGroup, Transported)\n\nnorm_ctrl <- trainControl(method = \"repeatedcv\", repeats = 5, classProbs = TRUE, summaryFunction = multiClassSummary)\n\nnorm_rec <- recipe(Transported ~ ., data = int_train) %>%\n  step_dummy(all_nominal_predictors())\n\n# my_cluster <- makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# set.seed(8584)\n# norm_m <- train(norm_rec, data = int_train, method = \"glm\", metric = \"Accuracy\", trControl = norm_ctrl)\n# \n# norm_m_acc <- getTrainPerf(norm_m)[1, \"TrainAccuracy\"]\n# \n# int_ctrl <- trainControl(method = \"repeatedcv\", repeats = 5, classProbs = TRUE, summaryFunction = multiClassSummary)\n# \n# int_function <- function(rec, f) {\n#   ir <- step_interact(recipe = rec, terms = !!f)\n#   return(ir)\n# }\n# # Map over pairs of vars to create int formulas\n# int_form <- map(.x = pairs, .f = \\(vp) formula(paste0(\"~starts_with('\", vp[1], \"'):starts_with('\", vp[2], \"')\")))\n# int_rec <- map(.x = int_form, .f = \\(form) int_function(norm_rec, f = form))\n# \n# set.seed(8584)\n# int_m <- map(.x = int_rec, .f = \\(r) train(r, data = int_train, method = \"glm\", metric = \"Accuracy\", trControl = int_ctrl))\n# \n# int_m_acc <- map_dbl(.x = int_m, .f = \\(m) getTrainPerf(m)[1, \"TrainAccuracy\"])\n# \n# anova_res <- map2(.x = int_m, .y =list(norm_m), .f = \\(m1, m2) anova(m1$finalModel, m2$finalModel, test = \"Chisq\"))\n# \n# diff_all_res <- map2(.x = int_m, .y = list(norm_m), .f = \\(m1, m2) compare_models_1way(m1, m2, metric = \"Accuracy\",\n#                                                                                        alternative = \"greater\"))\n# \n# stopCluster(my_cluster)\n# unregister()\n# \n# diff_all_res2 <-\n#   data.frame(Improvement = map_dbl(.x = diff_all_res, .f = \\(est) est$estimate),\n#              Resampled_Pvalue = map_dbl(.x = diff_all_res, .f = \\(p) p$p.value)) %>%\n#   bind_cols(., No_Int_Accuracy = norm_m_acc) %>%\n#   bind_cols(., Int_Accuracy = int_m_acc) %>%\n#   bind_cols(pairs_cols, .)\n# \n# diff_all_res2_anova <- \n#   data.frame(Deviance_improvement = map_dbl(.x = anova_res, .f = \\(x) x[[\"Deviance\"]][2]),\n#              Traditional_pvalue = map_dbl(.x = anova_res, .f = \\(x) x[[\"Pr(>Chi)\"]][2])) %>%\n#   bind_cols(., No_Int_Accuracy = norm_m_acc) %>%\n#   bind_cols(., Int_Accuracy = int_m_acc) %>%\n#   bind_cols(pairs_cols, .)\n# \n# save(diff_all_res2_anova, file = \"Extra/Anova pairwise interactions with all other variables.RData\")\n# save(diff_all_res2, file = \"Extra/Results pairwise interactions with all other variables.RData\")\n\nload(\"Extra/Anova pairwise interactions with all other variables.RData\")\nload(\"Extra/Results pairwise interactions with all other variables.RData\")\n\ndiff_all_res2_adj <- diff_all_res2 %>%\n  mutate(Resampled_pvalue_bh = p.adjust(Resampled_Pvalue, method = \"BH\"),\n         Resampled_pvalue_bon = p.adjust(Resampled_Pvalue, method = \"bonferroni\"))\ndiff_all_res2_anova %>%\n  filter(Deviance_improvement > 0)\n#> [1] V1                   V2                  \n#> [3] Deviance_improvement Traditional_pvalue  \n#> [5] No_Int_Accuracy      Int_Accuracy        \n#> <0 rows> (or 0-length row.names)\ndiff_all_res2_adj %>% \n  filter(Resampled_Pvalue <= 0.05) %>%\n  pivot_longer(cols = c(Int_Accuracy, No_Int_Accuracy)) %>%\n  mutate(Pairs = str_c(V1, \" and \", V2)) %>%\n  ggplot(., aes(x = reorder(Pairs, X = value), y = value, fill = name)) +\n  geom_col(position = position_dodge2()) +\n  coord_flip() +\n  labs(title = \"Unadjusted pairwise interactions\", x = \"Variable pairs\", y = \"Accuracy\") +\n  scale_fill_discrete(name = \"Models\", labels = c(\"With interactions\", \"Without interactions\")) +\n  theme(legend.position = \"top\")\np_bh <- diff_all_res2_adj %>% \n  filter(Resampled_pvalue_bh <= 0.2) %>%\n  pivot_longer(cols = c(Int_Accuracy, No_Int_Accuracy)) %>%\n  mutate(Pairs = str_c(V1, \" and \", V2)) %>%\n  ggplot(., aes(x = reorder(Pairs, X = value), y = value, fill = name)) +\n  geom_col(position = position_dodge2()) +\n  coord_flip() +\n  labs(title = \"Benjamini&Hochberg adjusted interactions\", x = \"Variable pairs\", y = \"Accuracy\") +\n  scale_fill_discrete(name = \"Models\", labels = c(\"With interactions\", \"Without interactions\"))\n\np_bon <- diff_all_res2_adj %>% \n  filter(Resampled_pvalue_bon <= 0.2) %>%\n  pivot_longer(cols = c(Int_Accuracy, No_Int_Accuracy)) %>%\n  mutate(Pairs = str_c(V1, \" and \", V2)) %>%\n  ggplot(., aes(x = reorder(Pairs, X = value), y = value, fill = name)) +\n  geom_col(position = position_dodge2()) +\n  coord_flip() +\n  labs(title = \"Bonferroni adjusted interactions\", x = \"Variable pairs\", y = \"Accuracy\") +\n  scale_fill_discrete(name = \"Models\", labels = c(\"With interactions\", \"Without interactions\"))\n\np_bh / p_bon + plot_layout(guides = \"collect\", axis_titles = \"collect\") & theme(legend.position = \"top\")\nint_vars_very_imp <- diff_all_res2_adj %>% \n  filter(Resampled_Pvalue <= 0.05) %>% \n  select(V1, V2) %>%\n  mutate(ForFormula = str_c(\"starts_with('\", V1, \"'):starts_with('\", V2, \"')\")) %>%\n  mutate(RevFormula = str_c(\"starts_with('\", V2, \"'):starts_with('\", V1, \"')\"))"},{"path":"chapter-6.html","id":"penalized-regression-for-interaction-exploration","chapter":"6 Interactions","heading":"6.4 Penalized regression for interaction exploration","text":"Let’s turn different interaction analysis ’ll use penalized regression see whether interactions prove beneficial model. use glmnet-function first fit model without interactions model interactions tune different parameters.\\(\\lambda\\) parameter controls penalty applied different variables maximize accuracy \\(\\alpha\\) controls weight applied penalty function \\(\\alpha = 1\\) signifies Lasso penalty penalty applied absolute regression coefficient \\(\\alpha = 0\\) signifies Ridge penalty penalty applied squared coefficient. case, glmnet model allows us tune mix factors gives best accuracy.\nFigure 6.9: Tuning results Lasso/Ridge regression without interaction effects.\nWithout interaction effects, regression model favoured pure Lasso regression (\\(\\alpha = 1\\)) penalty \\(\\lambda = 0.0001\\). important variables (highest coefficients) case HomePlanet, CryoSleep, Deck. final model used 33 36 variables resampled accuracy without interactions slightly 0.79.repeat process include interaction effects variables chosen previous section:see results penalized regression model interactions .\nFigure 6.10: Tuning results Lasso/Ridge regression interaction effects.\nregression model still favours Lasso (\\(\\alpha = 1\\)) higher penalty \\(\\lambda = 0.005\\). 516 total variables including interaction effects, selected 91 best accuracy somewhat 0.80. Compared model without interactions effects (accuracy = 0.79), ’s small improvement.can see top twenty variables penalized regression .\nFigure 6.11: Top variables Lasso/Ridge regression interaction effects. red blue lines indicate possible (arbitrary) cut-points importance.\n’s surprising see strongest effect Deck & Side, visually inspected Figure 6.3 looked effect interaction wasn’t large. visual interaction might look deceiving effect due overfitting.variables among 20 important almost interaction effects except CryoSleep see returning contenders like CryoSleep & HomePlanet top well CryoSleep & Deck, Destination & Deck . Although reduction gradual, big drop importance first three.However, since goal competition maximise accuracy, argument made interaction effects used see improve model performance.","code":"\ndf_pen <- train6 %>%\n  select(-c(Cabin, Name, LastName, PassengerCount, HomePlanetsPerGroup)) %>%\n    mutate(across(.cols = c(PassengerGroupSize, tidyselect::ends_with(\"PerGroup\")), .fns = as.integer))\n\nset.seed(8584)\nmy_pen_split <- initial_split(df_pen, prop = 0.8)\npen_train <- training(my_pen_split)\nmy_pen_folds <- vfold_cv(pen_train, v = 10, repeats = 5)\n\nmy_vars <- data.frame(Variables = names(pen_train)) %>%\n  mutate(Roles = if_else(Variables == \"PassengerId\", \"id\", \"predictor\"),\n         Roles = if_else(Variables == \"Transported\", \"outcome\", Roles))\n\npen_rec <- recipe(x = pen_train, vars = my_vars$Variables, roles = my_vars$Roles) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_zv(all_predictors())\n\nmy_acc <- metric_set(accuracy)\npen_ctrl <- control_grid(verbose = TRUE, save_pred = TRUE, save_workflow = TRUE)\npen_grid <- expand.grid(mixture = c(0.2, 0.6, 1), penalty = seq(1e-05, 1e-03, 5e-05))\n\nglmnet_mod <- logistic_reg(penalty = tune(), mixture = tune()) %>%\n  set_engine(\"glmnet\")\n\n# my_cluster <- makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# system.time({\n#   set.seed(8584)\n#   pen_tune <- glmnet_mod %>%\n#     tune_grid(pen_rec, resamples = my_pen_folds, metrics = my_acc, control = pen_ctrl, grid = pen_grid)\n# })\n# \n# save(pen_tune, file = \"Extra/Penalized regression without interactions.RData\")\n# \n# stopCluster(my_cluster)\n# unregister()\n\nload(\"Extra/Penalized regression without interactions.RData\")\npen_best <- fit_best(pen_tune)\npen_coef <- pen_best %>%\n  tidy() %>%\n  filter(estimate != 0) %>%\n  filter(term != \"(Intercept)\") %>%\n  pull(term)\n\nshow_best(pen_tune, metric = \"accuracy\", n = 20) %>%\n  mutate(mixture = as.factor(round(mixture, 2))) %>%\n  ggplot(aes(x = penalty, y = mean, label = mixture, colour = mixture)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Tune results without interactions\", x = \"Lambda penalty\", y = \"Resample accuracy\", colour = \"Alpha\")\nint_vars <- pen_coef %>%\n  str_split_i(., \"_\", 1) %>%\n  unique() %>%\n  combn(., 2, simplify = FALSE)\n\n# Map over pairs of vars to create int formula\nint_formula <- map_chr(.x = int_vars, .f = \\(vp) paste0(\"starts_with('\", vp[1], \"'):starts_with('\", vp[2], \"')\")) %>%\n  str_flatten(., collapse = \"+\") %>%\n  paste(\"~\", .) %>%\n  as.formula(.)\n\npen_int_rec <- recipe(x = pen_train, vars = my_vars$Variables, roles = my_vars$Roles) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_interact(int_formula) %>%\n  step_zv(all_predictors())\n\npen_grid <- expand.grid(mixture = c(0.2, 0.6, 1), penalty = seq(1e-04, 1e-02, 5e-04))\n  \n# my_cluster <- makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# clusterExport(cl = my_cluster, \"int_formula\")\n# \n# system.time({\n#   set.seed(8584)\n#   pen_int_tune <- glmnet_mod %>%\n#     tune_grid(pen_int_rec, resamples = my_pen_folds, metrics = my_acc, control = pen_ctrl, grid = pen_grid)\n# })\n# \n# save(pen_int_tune, file = \"Extra/Penalized regression with interactions.RData\")\n# \n# stopCluster(my_cluster)\n# unregister()\n\nload(\"Extra/Penalized regression with interactions.RData\")\nshow_best(pen_int_tune, metric = \"accuracy\", n = 40) %>%\n  mutate(mixture = as.factor(round(mixture, 2))) %>%\n  ggplot(aes(x = penalty, y = mean, label = mixture, colour = mixture)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Tune results with interactions\", x = \"Lambda penalty\", y = \"Resample accuracy\", colour = \"Alpha\")\n# pen_int_best <- fit_best(pen_int_tune)\n# save(pen_int_best, file = \"Extra/Best penalized regression with interactions.RData\")\nload(\"Extra/Best penalized regression with interactions.RData\")\npen_int_coef <- pen_int_best %>%\n  tidy()\n\npen_int_coef %>%\n  select(-penalty) %>%\n  filter(estimate != 0 & term != \"(Intercept)\") %>%\n  arrange(desc(abs(estimate))) %>%\n  slice(1:20) %>%\n  ggplot(., aes(x = abs(estimate), y = reorder(term, abs(estimate)))) +\n  geom_col() +\n  geom_vline(aes(xintercept = 0.50), colour = \"red\", linetype = \"dashed\") +\n  geom_vline(aes(xintercept = 0.25), colour = \"blue\", linetype = \"dashed\") +\n  labs(x = \"Regression coefficient (abs)\", y = \"Variable\") +\n  theme(legend.position = \"none\")\npen_int_vars <- pen_int_coef %>%\n  select(-penalty) %>%\n  filter(abs(estimate) != 0 & term != \"(Intercept)\") %>%\n  filter(str_detect(term, \"_x_\")) %>%\n  mutate(V1 = str_split_i(term, \"_x_\", 1),\n         V1 = str_split_i(term, \"_\", 1),\n         V2 = str_split_i(term, \"_x_\", 2),\n         V2 = str_split_i(V2, \"_\", 1),\n         ForFormula = str_c(\"starts_with('\", V1, \"'):starts_with('\", V2, \"')\"),\n         RevFormula = str_c(\"starts_with('\", V2, \"'):starts_with('\", V1, \"')\")) %>%\n  select(V1, V2, ForFormula, RevFormula)\n\nsave(pen_int_vars, file = \"Extra/Best interactions.RData\")"},{"path":"chapter-6.html","id":"tree-model-interactions","chapter":"6 Interactions","heading":"6.5 Tree model interactions","text":"third can use indirectly discover interaction effects use tree-based model like randomForest. Kuhn Johnson explain better book essence, tree models nature interaction models since look thresholds different variables split tree branches splits often involve another variable next (previous) junction.results randomForest model doesn’t provide interactions ranks original variables based importance can used model interaction effects second stage.\nFigure 6.12: Variable importance based ranger tree model\ntree model heavily favours amenity variables, especially TotalSpent feature ’ve created. However, feature penalized zero penalized regression, likely correlates amenity variables. amenities , however, represented among variables best penalized results ’ll stick going forward.","code":"\ndf_tree <- train6 %>%\n  mutate(across(.cols = c(PassengerGroupSize, Solo, LargeGroup, TravelTogether, tidyselect::ends_with(\"PerGroup\")),\n                .fns = as.integer))\n\nset.seed(8584)\nmy_tree_split <- initial_split(df_tree, prop = 0.8)\ntree_train <- training(my_tree_split)\n\nmy_vars <- data.frame(Variables = names(tree_train)) %>%\n  mutate(Roles = if_else(Variables %in% c(\"PassengerId\", \"Cabin\", \"Name\", \"LastName\", \"PassengerCount\", \"HomePlanetsPerGroup\"),\n                         \"id\", \"predictor\"),\n         Roles = if_else(Variables == \"Transported\", \"outcome\", Roles))\n\ntree_rec <- recipe(x = tree_train, vars = my_vars$Variables, roles = my_vars$Roles) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_zv(all_predictors())\n\ntree_baked <- tree_rec %>%\n  prep() %>%\n  bake(new_data = NULL) %>%\n  select(-c(Cabin, Name, LastName, PassengerCount, HomePlanetsPerGroup))\n\n# my_cluster <- makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# system.time({\n#   rf_mod <- ranger::ranger(Transported ~ . -PassengerId, data = tree_baked, num.trees = 1000, importance = \"impurity\",\n#                    num.threads = detectCores() - 1, seed = 8584)\n# })\n# \n# save(rf_mod, file = \"Extra/Ranger tree model variable importance.RData\")\n# \n# stopCluster(my_cluster)\n# unregister()\n\nload(\"Extra/Ranger tree model variable importance.RData\")\n\nrf_imp <- tibble(Predictor = names(rf_mod$variable.importance),\n                 Importance = unname(rf_mod$variable.importance))\nggplot(rf_imp, aes(x = reorder(Predictor, Importance), y = Importance)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  xlab(\"\")"},{"path":"chapter-7.html","id":"chapter-7","chapter":"7 Feature selection and elimination","heading":"7 Feature selection and elimination","text":"Now created several new features discovered promising interaction effects, must explore potential improve models don’t. Kuhn Johnson recommend several methods feature selection elimination ’ll explore.Please note chunks can take many (48-96) hours run, depending setup. reduce computation time, lower size-variables smaller grid search.","code":""},{"path":"chapter-7.html","id":"recursive-feature-elimination","chapter":"7 Feature selection and elimination","heading":"7.1 Recursive feature elimination","text":"Recursive feature elimination process begins model includes features systematized resampling process removes sets variables see whether improves performance. goal process converge set predictor variables produce best results.’ll use original variables well interaction effects ’ve identified previous chapter.\nFigure 7.1: Estimated performance recursive feature elimination based number variables included.\nresults RFE-process indicate accuracy doesn’t improve beyond 110 variables. Let’s save .","code":"\nrfe_df <- train6 %>%\n  select(-c(Cabin, Name, LastName, PassengerCount, HomePlanetsPerGroup))\n\nset.seed(8584)\nrfe_split <- initial_split(rfe_df, prop = 0.8)\nrfe_train <- training(rfe_split)\n\nrfe_vars <- data.frame(Variables = names(rfe_df)) %>%\n  mutate(Roles = case_when(Variables == \"PassengerId\" ~ \"id\",\n                           Variables == \"Transported\" ~ \"outcome\",\n                           .default = \"predictor\"))\n\nint_formula <- pen_int_vars %>%\n  select(ForFormula, RevFormula) %>%\n  unlist() %>%\n  unname() %>%\n  str_flatten(., collapse = \"+\") %>%\n  str_c(\"~\", .) %>%\n  as.formula(.)\n\nrfe_rec <- recipe(x = rfe_train, vars = rfe_vars$Variables, roles = rfe_vars$Roles) %>%\n  step_normalize(Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, PassengerGroup, CabinNumber, TotalSpent,\n                 TotalSpentPerGroup, LastNameAsNumber) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_interact(int_formula) %>%\n  step_zv(all_predictors())\n\nmany_stats <- function(data, lev = levels(data$obs), model = NULL) {\n    c(twoClassSummary(data = data, lev = levels(data$obs), model),\n      prSummary(data = data, lev = levels(data$obs), model),\n      mnLogLoss(data = data, lev = levels(data$obs), model),\n      defaultSummary(data = data, lev = levels(data$obs), model))\n}\nrfe_funcs <- caret::caretFuncs\nrfe_funcs$summary <- many_stats\nrfe_funcs$fit <- function (x, y, first, last, ...) \n  train(x, y, trControl = trainControl(classProbs = TRUE), ...)\nrfe_sizes <- seq(10, 350, 10)\nrfe_ctrl <- rfeControl(method = \"repeatedcv\", repeats = 5, functions = rfe_funcs, returnResamp = \"all\", verbose = FALSE)\n\n# my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# snow::clusterEvalQ(my_cluster, library(recipes))\n# snow::clusterExport(my_cluster, \"int_formula\")\n# \n# system.time({\n#   set.seed(8584)\n#   rfe_acc <- rfe(rfe_rec, data = rfe_train, method = \"glm\", family = \"binomial\", metric = \"Accuracy\", sizes = rfe_sizes,\n#                  rfeControl = rfe_ctrl)\n# })\n# \n# save(rfe_acc, file = \"Extra/Recursive feature elimination with interactions.RData\")\n# \n# stopCluster(my_cluster)\n# unregister()\n\nload(\"Extra/Recursive feature elimination with interactions.RData\")\nrfe_avg_res <- rfe_acc$results %>%\n  select(Variables, Accuracy)\n\nrfe_avg_res %>%\n  ggplot(data = ., aes(x = Variables, y = Accuracy)) +\n  geom_point() +\n  geom_line() +\n  geom_vline(xintercept = 110, linetype = \"dashed\", colour = \"blue\", size = 1)\nrfe_best <- rfe_acc[[\"variables\"]] %>%\n  filter(Variables == 110) %>%\n  select(var, Resample) %>%\n  nest(.by = Resample) %>%\n  left_join(., rfe_acc[[\"resample\"]] %>% \n              filter(Variables == 110) %>% \n              select(Accuracy, Resample),\n            by = \"Resample\")\n\nrfe_best_vars <- rfe_best %>%\n  filter(Accuracy == max(Accuracy)) %>%\n  pull(data) %>%\n  unlist(.)\n\nnames(rfe_best_vars) <- rfe_best_vars"},{"path":"chapter-7.html","id":"simulated-annealing","chapter":"7 Feature selection and elimination","heading":"7.2 Simulated annealing","text":"Kuhn Johnson describe process simulated annealing detail book main purpose iterate random subsets predictor variables calculate performance optimal set found. process starts given set variables adds removes subsets evaluates add performance. , new subset kept tested others. process uses randomness avoid converging subset variables high performance particular resample (local optima).’ll use setup recursive feature elimination . initiate process random subset 30% variables.\nFigure 7.2: Estimated performance internal resamples simulated annealing.\nresults internal simulated annealing process suggest initial random set 30% variables relatively high accuracy improvement made iterations, based average accuracy increasesfor first 100 iterations.\nFigure 7.3: Estimated performance external resamples simulated annealing.\nexternal resampling used check performance different iterations since correlates relatively well internal resamples, can conclude internal resamples haven’t overfitted data.\nFigure 7.4: Estimated performance best resample simulated annealing.\nfinal results simulated annealing process indicate subset 142 variables produces best accuracy, close 0.81. possible iterations ’ve revealed improvements since subset close one produced RFE-model (110), ’ll assume number iterations enough.Let us save best variables process possible later use.","code":"\nsa_df <- train6 %>%\n  select(-c(Cabin, Name, LastName, PassengerCount, HomePlanetsPerGroup))\n\nset.seed(8584)\nsa_split <- initial_split(sa_df, prop = 0.8)\nsa_train <- training(sa_split)\n\nsa_vars <- data.frame(Variables = names(sa_df)) %>%\n  mutate(Roles = case_when(Variables == \"PassengerId\" ~ \"id\",\n                           Variables == \"Transported\" ~ \"outcome\",\n                           .default = \"predictor\"))\n\nint_formula <- pen_int_vars %>%\n  select(ForFormula, RevFormula) %>%\n  unlist() %>%\n  unname() %>%\n  str_flatten(., collapse = \"+\") %>%\n  str_c(\"~\", .) %>%\n  as.formula(.)\n\nsa_rec <- recipe(x = sa_train, vars = sa_vars$Variables, roles = sa_vars$Roles) %>%\n  step_normalize(Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck, PassengerGroup, CabinNumber, TotalSpent,\n                 TotalSpentPerGroup, LastNameAsNumber) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_interact(int_formula) %>%\n  step_zv(all_predictors())\n\nsa_bake <- sa_rec %>% prep() %>% bake(new_data = NULL)\n\nsa_funcs <- caretSA\nsa_funcs$fitness_extern <- many_stats\nsa_funcs$initial <- function(vars, prob = 0.30, ...) { # Change the prob to begin from a lower or higher subset\n  sort(sample.int(vars, size = floor(vars * prob) + 1))\n}\n\n# Inner control\nsa_ctrl_inner <- trainControl(method = \"boot\", p = 0.90, number = 1, summaryFunction = many_stats, classProbs = TRUE, \n                        allowParallel = FALSE)\n\n# Outer control for SA\nsa_ctrl_outer <- safsControl(method = \"cv\", metric = c(internal = \"Accuracy\", external = \"Accuracy\"), \n                       maximize = c(internal = TRUE, external = TRUE), functions = sa_funcs, improve = 20, returnResamp = \"all\",\n                       verbose = FALSE, allowParallel = TRUE)\n\n# my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# snow::clusterExport(cl = my_cluster, \"int_formula\")\n# \n# system.time({\n#   set.seed(8485)\n#   sa_30pct_init <- safs(sa_rec, data = sa_train, iters = 500, safsControl = sa_ctrl_outer, method = \"glm\",\n#                             trControl = sa_ctrl_inner, metric = \"Accuracy\")\n# })\n# \n# save(sa_30pct_init, file = \"Extra/Simulated annealing.RData\")\n# \n# snow::stopCluster(my_cluster)\n# unregister()\n\nload(\"Extra/Simulated annealing.RData\")\nsa_acc_int <- sa_30pct_init$internal\nsa_acc_int2 <- sa_acc_int %>%\n  group_by(Iter) %>%\n  summarise(Accuracy = sum(Accuracy) / length(unique(sa_acc_int$Resample))) %>%\n  ungroup() %>%\n  mutate(Resample = \"Averaged\") %>%\n  bind_rows(sa_acc_int, .) %>%\n  mutate(colour_grp = if_else(Resample == \"Averaged\", \"yes\", \"no\"))\n\nsa_avg_int <- sa_acc_int2 %>% filter(Resample == \"Averaged\") %>% select(Iter, Accuracy)\n  \nggplot(sa_acc_int2, aes(x = Iter, y = Accuracy, colour = colour_grp)) +\n  geom_point() +\n  facet_wrap(~Resample) +\n  theme(legend.position = \"none\")\nsa_acc_ext <- sa_30pct_init$external\nsa_acc_ext2 <- sa_acc_ext %>%\n  group_by(Iter) %>%\n  summarise(Accuracy = sum(Accuracy) / length(unique(sa_acc_ext$Resample))) %>%\n  ungroup() %>%\n  mutate(Resample = \"Averaged\") %>%\n  bind_rows(sa_acc_ext, .) %>%\n  mutate(colour_grp = if_else(Resample == \"Averaged\", \"yes\", \"no\"))\n\nsa_avg_ext <- sa_acc_ext2 %>% filter(Resample == \"Averaged\") %>% select(Iter, Accuracy)\n\next_int_corr <- round(cor(sa_avg_int$Accuracy, sa_avg_ext$Accuracy), 2)\n\nggplot(mapping = aes(x = Iter, y = Accuracy)) +\n  geom_point(data = sa_avg_int, aes(colour = \"Internal\")) +\n  geom_point(data = sa_avg_ext, aes(colour = \"External\")) +\n  geom_label(data = sa_avg_ext, x = 5, y = 0.795, label = str_c(\"Corr: \", ext_int_corr)) +\n  labs(colour = \"Estimate\") +\n  scale_colour_manual(values = c(\"Internal\" = \"red\", \"External\" = \"green\"))\nsa_final <- sa_30pct_init$sa\nsa_final2 <- data.frame(Iter = sa_final[[\"internal\"]]$Iter, Accuracy = sa_final[[\"internal\"]]$Accuracy,\n                                Subset_Size = unlist(lapply(sa_final[[\"subsets\"]], length))) %>%\n  pivot_longer(-Iter)\n\nggplot(sa_final2, aes(x = Iter, y = value)) +\n  geom_point() +\n  geom_vline(xintercept = 488, linetype = \"dashed\", colour = \"blue\", size = 1, alpha = 0.6) +\n  facet_wrap(~name, nrow = 2, ncol = 1, scales = \"free_y\")\nsa_best_vars <- sa_30pct_init[[\"optVariables\"]]"},{"path":"chapter-7.html","id":"genetic-algorithm","chapter":"7 Feature selection and elimination","heading":"7.3 Genetic algorithm","text":"final process feature selection ’ll use genetic algorithm. Similar simulated annealing, starts subset variables first generation iterates different generation (external resampling) selects subsets variables ‘mating’ see whether new “offspring” improves performance. process also involves steps avoid local optima.\nFigure 7.5: Estimated performance internal resamples genetic algorithm.\ninner resamples genetic algorithm suggest plateau around twenty generations (iterations).\nFigure 7.6: Estimated performance external resamples genetic algorithm.\ngenetic algorithm, see internal folds got better results indicate selections subsets variables (populations) overfit data external validations (number generations) found general population mix hopefully better describes unseen data.Let’s save best variables process possible later use.","code":"\nga_df <- train6 %>%\n  select(-c(Cabin, Name, LastName, PassengerCount, HomePlanetsPerGroup))\n\nset.seed(8584)\nga_split <- initial_split(ga_df, prop = 0.8)\nga_train <- training(ga_split)\n\nga_vars <- data.frame(Variables = names(ga_df)) %>%\n  mutate(Roles = case_when(Variables == \"PassengerId\" ~ \"id\",\n                           Variables == \"Transported\" ~ \"outcome\",\n                           .default = \"predictor\"))\n\nint_formula <- pen_int_vars %>%\n  select(ForFormula, RevFormula) %>%\n  unlist() %>%\n  unname() %>%\n  str_flatten(., collapse = \"+\") %>%\n  str_c(\"~\", .) %>%\n  as.formula(.)\n\nga_rec <- recipe(x = ga_train, vars = ga_vars$Variables, roles = ga_vars$Roles) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_interact(int_formula) %>%\n  step_zv(all_predictors()) %>%\n  step_corr(all_numeric_predictors(), threshold = 0.5)\n\nga_funcs <- caretGA\nga_funcs$fitness_extern <- many_stats\n\n# Inner control\nga_ctrl_inner <- trainControl(method = \"boot\", p = 0.90, number = 1, summaryFunction = many_stats, classProbs = TRUE,\n                        allowParallel = FALSE)\n\n# Outer control for SA\nga_ctrl_outer <- gafsControl(method = \"cv\", metric = c(internal = \"Accuracy\", external = \"Accuracy\"),\n                       maximize = c(internal = TRUE, external = TRUE), functions = ga_funcs, returnResamp = \"all\",\n                       verbose = FALSE, allowParallel = TRUE)\n\n# my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# snow::clusterExport(cl = my_cluster, \"int_formula\")\n# \n# system.time({\n#   set.seed(8584)\n#   ga_acc <- gafs(ga_rec, data = ga_train, iters = 50, gafsControl = ga_ctrl_outer, method = \"glm\",\n#                  trControl = ga_ctrl_inner, metric = \"Accuracy\")\n# })\n# \n# save(ga_acc, file = \"Extra/Genetic algorithm feature selection.RData\")\n# \n# snow::stopCluster(my_cluster)\n# unregister()\n\nload(\"Extra/Genetic algorithm feature selection.RData\")\nga_acc_int <- ga_acc$internal\nga_acc_int2 <- ga_acc_int %>%\n  group_by(Iter) %>%\n  summarise(Accuracy = sum(Accuracy) / length(unique(ga_acc_int$Resample))) %>%\n  ungroup() %>%\n  mutate(Resample = \"Averaged\") %>%\n  bind_rows(ga_acc_int, .) %>%\n  mutate(colour_grp = if_else(Resample == \"Averaged\", \"yes\", \"no\"))\n\nga_avg_int <- ga_acc_int2 %>% filter(Resample == \"Averaged\") %>% select(Iter, Accuracy)\n  \nggplot(ga_acc_int2, aes(x = Iter, y = Accuracy, colour = colour_grp)) +\n  geom_point() +\n  facet_wrap(~Resample) +\n  theme(legend.position = \"none\")\nga_acc_ext <- ga_acc$external\nga_acc_ext2 <- ga_acc_ext %>%\n  group_by(Iter) %>%\n  summarise(Accuracy = sum(Accuracy) / length(unique(ga_acc_ext$Resample))) %>%\n  ungroup() %>%\n  mutate(Resample = \"Averaged\") %>%\n  bind_rows(ga_acc_ext, .) %>%\n  mutate(colour_grp = if_else(Resample == \"Averaged\", \"yes\", \"no\"))\n\nga_avg_ext <- ga_acc_ext2 %>% filter(Resample == \"Averaged\") %>% select(Iter, Accuracy)\n\nga_ext_int_corr <- round(cor(ga_avg_int$Accuracy, ga_avg_ext$Accuracy), 2)\n\nggplot(mapping = aes(x = Iter, y = Accuracy)) +\n  geom_point(data = ga_avg_int, aes(colour = \"Internal\")) +\n  geom_point(data = ga_avg_ext, aes(colour = \"External\")) +\n  geom_label(data = ga_avg_ext, x = 5, y = 0.803, label = str_c(\"Corr: \", ga_ext_int_corr)) +\n  labs(colour = \"Estimate\") +\n  scale_colour_manual(values = c(\"Internal\" = \"red\", \"External\" = \"green\"))\nga_best_vars <- ga_acc[[\"optVariables\"]]"},{"path":"chapter-7.html","id":"check-performance-with-random-subsets","chapter":"7 Feature selection and elimination","heading":"7.4 Check performance with random subsets","text":"results three feature selection processes suggest optimal set variables (including dummy variables interactions) 110 (RFE) 174 (SA) genetic algorithm coming 136.get sense well processes selected subsets variables, can run iteration takes random subsets evaluates performance. tell us processes better random chance. ’ll use smallest subset (RFE) reduce computational demands.\nFigure 7.7: Comparison different feature selection results random subset result.\nseems visually feature selection methods outperform random variable subsets time let’s quantify differences test significance.\nFigure 7.8: Tests significance different feature selection methods random samples. figure shows medians (Wilcoxon) means(t-test) accuracy significantly higher results produced methods compared ones produced random subsets.\nWilcoxon test checks whether median difference accuracy processed sample random sample significant doesn’t require distribution differences paired samples normal. t.test compares means require sample differences relatively normal. null hypothesis cases accuracies processed samples smaller equal accuracies random samples low p-values mean processed samples significantly greater accuracies random samples.see methods significant improvement random sample look back Figure 7.7, can see accuracy results seem comparable methods. Let’s therefore save variables SA process since offered best results.","code":"\nrand_subset_size <- length(rfe_best_vars)\n\nrfe_bake <- rfe_rec %>%\n  prep() %>%\n  bake(new_data = NULL) %>%\n  select(-PassengerId)\n\nfull_vars <- rfe_bake %>% names(.)\nhalf_full_vars <- round(length(full_vars) / 2, 0)\nmap_seq <- 1:half_full_vars # Number of iterations half of total number of variables to ensure sufficient combinations\n\nrand_subset <- map(map_seq, .f = \\(x) sample(full_vars, rand_subset_size))\nrand_data <- map(rand_subset, .f = \\(x) rfe_bake %>% dplyr::select(Transported, x))\nrand_rec <- map(rand_data, .f = \\(df) recipe(Transported ~ ., data = df))\n\nsubset_ctrl <- trainControl(method = \"cv\", classProbs = TRUE, summaryFunction = many_stats)\n\n# my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# system.time({\n#   subset_model <- map2(.x = rand_rec, .y = rand_data,\n#                        .f = \\(rec, df) train(rec, data = df, method = \"glm\", trControl = subset_ctrl, metric = \"Accuracy\"))\n# })\n# \n# subset_perf <- map(subset_model, .f = \\(m) getTrainPerf(m))\n# \n# save(subset_perf, file = \"Extra/Random subsets performance.RData\")\n# \n# snow::stopCluster(my_cluster)\n# unregister()\n\nload(\"Extra/Random subsets performance.RData\")\nrf_random_avg <- map_dbl(subset_perf, .f = \\(x) x$TrainAccuracy) %>%\n  enframe()\n\nggplot() +\n  geom_point(data = rfe_avg_res, aes(x = Variables, y = Accuracy, colour = \"RFE\")) +\n  geom_point(data = sa_avg_ext, aes(x = Iter, y = Accuracy, colour = \"SA\")) +\n  geom_point(data = ga_avg_ext, aes(x = Iter, y = Accuracy, colour = \"GA\")) +\n  geom_point(data = rf_random_avg, aes(x = name, y = value, colour = \"Random\")) +\n  scale_colour_manual(values = c(\"RFE\" = \"green\", \"RFE Tree\" = \"blue\", \"SA\" = \"orange\", \"GA\" = \"red\", \"Random\" = \"darkgrey\")) +\n  labs(x = \"Variables(RFE) or iterations\", y = \"Accuracy\", colour = \"Method\") +\n  lims(y = c(0.6, 0.8))\nmy_sample_size <- length(rf_random_avg$name)\n\nrandom_avg_acc <- rf_random_avg$value\nrfe_avg_acc <- sample(rfe_avg_res$Accuracy, my_sample_size, replace = TRUE)\nsa_avg_acc <- sample(sa_avg_ext$Accuracy, my_sample_size, replace = TRUE)\nga_avg_acc <- sample(ga_avg_ext$Accuracy, my_sample_size, replace = TRUE)\n\np_wilcox_rfe <- wilcox.test(x = rfe_avg_acc, y = random_avg_acc, paired = TRUE, alternative = \"greater\")$p.value\np_ttest_rfe <- t.test(x = rfe_avg_acc, y = random_avg_acc, paired = TRUE, alternative = \"greater\")$p.value\n\np_wilcox_sa <- wilcox.test(x = sa_avg_acc, y = random_avg_acc, paired = TRUE, alternative = \"greater\")$p.value\np_ttest_sa <- t.test(x = sa_avg_acc, y = random_avg_acc, paired = TRUE, alternative = \"greater\")$p.value\n\np_wilcox_ga <- wilcox.test(x = ga_avg_acc, y = random_avg_acc, paired = TRUE, alternative = \"greater\")$p.value\np_ttest_ga <- t.test(x = ga_avg_acc, y = random_avg_acc,  paired = TRUE, alternative = \"greater\")$p.value\n\np_tests <- data.frame(test = rep(c(\"Wilcoxon paired\", \"t.test paired\"), 3),\n                      colour_grp = rep(c(\"RFE\", \"SA\", \"GA\"), 2),\n                      value = c(p_wilcox_rfe, p_wilcox_sa, p_wilcox_ga,\n                                p_ttest_rfe, p_ttest_sa, p_ttest_ga))\n\nggplot(p_tests, aes(x = test, y = value, colour = colour_grp)) +\n  geom_point(size = 5) +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", colour = \"red\", show.legend = FALSE) +\n  scale_colour_manual(values = c(\"RFE\" = \"green\", \"SA\" = \"orange\", \"GA\" = \"red\", \"size\" = \"none\")) +\n  labs(x = \"Tests of difference\", y = \"P value\", colour = \"Method\")\nbest_vars <- sa_best_vars\nsave(best_vars, file = \"Extra/Best variables.RData\")"},{"path":"chapter-8.html","id":"chapter-8","chapter":"8 Final model tuning","heading":"8 Final model tuning","text":"exploration data far yielded set features, including second level interactions, think offers best accuracy. ’ve tested several feature selection processes gotten insight models performance resampling evaluations.Now must decide models, assembly models, want use final prediction. many different model engines can handle classification problems, different pros cons. list ones using:Exact Bayes model , row data, find rows exact set predictor values predict outcome row based probable outcome group. datasets, impractical since, enough variables, wouldn’t observations (rows) data exactly .traditional tree-model, variables split branches many splits split point find minimizes criterion, often Gini impurity measures proportions misclassified records. case two classes, like problem, Gini impurity given \\(p(1-p)\\) p proportion missclassified records partition.","code":""},{"path":"chapter-8.html","id":"complete-preprocess","chapter":"8 Final model tuning","heading":"8.1 Complete preprocess","text":"Let’s summarise entire preprocess training data get models.","code":""},{"path":"chapter-8.html","id":"logistic-regression---glm","chapter":"8 Final model tuning","heading":"8.2 Logistic regression - GLM","text":"Based resamples, seems best threshold probability cutoff 0.46 instead normal 0.5. best accuracy seem able get just 0.8 glm-model.","code":"\nglm_final_mod <- logistic_reg() %>%\n  set_engine(\"glm\", family = \"binomial\")\n\nglm_final_wf <- workflow() %>%\n  add_recipe(final_rec) %>%\n  add_model(glm_final_mod)\n\nglm_control <- control_resamples(save_pred = TRUE, save_workflow = TRUE)\n\n# my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# snow::clusterExport(cl = my_cluster, \"int_formula\")\n# \n# system.time({\n#   set.seed(8584)\n#   glm_final_fit_resamples <- fit_resamples(glm_final_wf, final_folds, control = glm_control)\n# })\n# \n# save(glm_final_fit_resamples, file = \"Extra/Final GLM tune.RData\")\n# \n# snow::stopCluster(my_cluster)\n# unregister()\n\nload(\"Extra/Final GLM tune.RData\")\n\nbind_preds <- function(df, t) {\n  res <- map(.x = t, .f = \\(x) df %>% mutate(\"Pred_{{x}}\" := if_else(.pred_True < x, \"False\", \"True\"), .keep = \"none\"))\n  res <- bind_cols(df, res, .name_repair = \"unique_quiet\")\n  return(res)\n}\n\ncalc_acc <- function(df) {\n  res <- df %>% mutate(across(.cols = starts_with(\"Pred\"), .fns = as.factor),\n                       across(.cols = starts_with(\"Pred\"), .fns = ~accuracy_vec(truth = df$Transported, estimate = .x)))\n  return(res)\n}\n\nglm_resample_pred <- collect_predictions(glm_final_fit_resamples, summarize = TRUE)\n\nglm_thresholds <- seq(0.1, 0.9, 0.05)\n\nglm_resample_acc <- glm_resample_pred %>%\n  select(Transported, .pred_False, .pred_True) %>%\n  bind_preds(., glm_thresholds) %>%\n  calc_acc(.) %>%\n  summarise(across(.cols = starts_with(\"Pred\"), .fns = mean)) %>%\n  pivot_longer(everything()) %>%\n  mutate(name = as.numeric(str_split_i(name, \"_\", 2)))\n\nglm_p1 <- ggplot(glm_resample_acc, aes(x = name, y = value)) +\n  geom_point() +\n  labs(x = \"Probability threshold\", y = \"Accuracy\") +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 90)) +\n  scale_x_continuous(breaks = glm_thresholds)\n\nglm_thresholds2 <- seq(0.4, 0.5, 0.01)\n\nglm_resample_acc2 <- glm_resample_pred %>%\n  select(Transported, .pred_False, .pred_True) %>%\n  bind_preds(., glm_thresholds2) %>%\n  calc_acc(.) %>%\n  summarise(across(.cols = starts_with(\"Pred\"), .fns = mean)) %>%\n  pivot_longer(everything()) %>%\n  mutate(name = as.numeric(str_split_i(name, \"_\", 2)))\n\nglm_p2 <- ggplot(glm_resample_acc2, aes(x = name, y = value)) +\n  geom_point() +\n  labs(x = \"Probability threshold\", y = \"Accuracy\") +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 90)) +\n  scale_x_continuous(breaks = glm_thresholds2)\n\nglm_p1 + glm_p2 + plot_layout(axis_titles = \"collect_y\")\n\nglm_final_fit <- fit(glm_final_wf, final_train)\nglm_final_pred <- predict(glm_final_fit, final_test, type = \"prob\") %>%\n  mutate(Prediction = as.factor(if_else(.pred_True < 0.46, \"False\", \"True\")))\nglm_final_acc <- accuracy_vec(final_test$Transported, glm_final_pred$Prediction)"},{"path":"chapter-8.html","id":"penalized-logistic-regression---glmnet","chapter":"8 Final model tuning","heading":"8.3 Penalized logistic regression - GLMNET","text":"","code":"\n# glmnet_final_mod <- logistic_reg(penalty = tune(), mixture = tune()) %>%\n#   set_engine(\"glmnet\", family = \"binomial\")\n# \n# glmnet_final_wf <- glm_final_wf %>%\n#   update_model(glmnet_final_mod)\n# \n# my_acc <- metric_set(accuracy)\n# glmnet_ctrl <- control_grid(save_pred = TRUE, save_workflow = TRUE)\n# glmnet_grid <- expand.grid(mixture = 1, penalty = seq(1e-07, 1e-04, 1e-06))\n# \n# # my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# # registerDoSNOW(my_cluster)\n# # \n# # system.time({\n# #   set.seed(8584)\n# #   glmnet_final_tune <- glmnet_final_wf %>%\n# #     tune_grid(object = ., resamples = final_folds, metrics = my_acc, control = glmnet_ctrl, grid = glmnet_grid)\n# # })\n# # \n# # save(glmnet_final_tune, file = \"Extra/Final glmnet tune.RData\")\n# # \n# # snow::stopCluster(my_cluster)\n# # unregister()\n# \n# load(\"Extra/Final glmnet tune.RData\")\n# \n# show_best(glmnet_final_tune, metric = \"accuracy\", n = 20) %>%\n#   mutate(mixture = as.factor(round(mixture, 2))) %>%\n#   ggplot(aes(x = penalty, y = mean, label = mixture, colour = mixture)) +\n#   geom_line() +\n#   geom_point() +\n#   labs(title = \"Final tune results\", x = \"Lambda penalty\", y = \"Resample accuracy\", colour = \"Alpha\")\n# \n# set.seed(8584)\n# glmnet_final_fit <- fit_best(glmnet_final_tune)\n# \n# glmnet_final_pred <- predict(glmnet_final_fit, final_test, type = \"class\")\n# glmnet_final_acc <- accuracy_vec(final_test$Transported, glmnet_final_pred$.pred_class)"},{"path":"chapter-8.html","id":"generalized-additive-models---gam","chapter":"8 Final model tuning","heading":"8.4 Generalized additive models - GAM","text":"","code":"\ngam_final_mod <- gen_additive_mod(select_features = FALSE) %>%\n  set_engine(\"mgcv\") %>%\n  set_mode(\"classification\")\n\nf <- reformulate(setdiff(colnames(final_train), \"Transported\"), response = \"Transported\")\n\nset.seed(8584)\ngam_final_fit <- fit(object = gam_final_mod, formula = f, data = final_train)\n\ngam_final_pred <- predict(gam_final_fit, final_test, type = \"class\")\ngam_final_acc <- accuracy_vec(final_test$Transported, gam_final_pred$.pred_class)"},{"path":"chapter-8.html","id":"svm","chapter":"8 Final model tuning","heading":"8.5 SVM","text":"parsnip package offers three different SVM engines.SVM_linear defines SVM model uses linear class boundary. classification, model tries maximize width margin classes using linear class boundary. single tuning parameter (named cost parsnip) determines strict misclassification treated. stricter cost, greater risk overfitting.SVM_poly model tries maximize width margin classes using polynomial class boundary. three tuning parameters parsnip: cost, degree scale. cost-parameter linear model degree-parameter determines degree polynomial. Lower degrees might find polynomial functions underfit higher might overfit. scale factor used scale data isn’t necessary predictors already scaled.SVM_rbf model stands Radial Basis Function tries maximize width margin classes using nonlinear class boundary. useful predictors overlap since maps data infinite dimension space. two tuning parameters: cost \\(\\sigma\\). cost-parameter two SVM-models \\(\\sigma\\)-parameter can seen weighting parameter adjust influence nearby data.","code":"\n# svm_linear_final_mod <- svm_linear(cost = tune()) %>%\n#   set_mode(\"classification\") %>%\n#   set_engine(\"kernlab\")\n# \n# svm_linear_final_wf <- glm_final_wf %>%\n#   update_model(svm_linear_final_mod)\n# \n# my_acc <- metric_set(accuracy)\n# svm_linear_ctrl <- control_grid(save_pred = TRUE, save_workflow = TRUE)\n# svm_linear_grid <- expand.grid(cost = seq(0, 2, 0.2))\n# \n# # my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# # registerDoSNOW(my_cluster)\n# # \n# # system.time({\n# #   set.seed(8584)\n# #   svm_linear_final_tune <- svm_linear_final_wf %>%\n# #     tune_grid(object = ., resamples = final_folds, metrics = my_acc, control = svm_linear_ctrl, grid = svm_linear_grid)\n# # })\n# # \n# # save(svm_linear_final_tune, file = \"Extra/Final SVM linear tune.RData\")\n# # \n# # snow::stopCluster(my_cluster)\n# # unregister()\n# \n# load(\"Extra/Final SVM linear tune.RData\")\n# \n# show_best(svm_linear_final_tune, metric = \"accuracy\", n = 20) %>%\n#   ggplot(aes(x = cost, y = mean)) +\n#   geom_line() +\n#   geom_point() +\n#   scale_x_continuous(breaks = seq(0, 2, 0.2)) +\n#   labs(title = \"Final tune results\", x = \"Cost penalty\", y = \"Resample accuracy\")\n# \n# set.seed(8584)\n# svm_linear_final_fit <- fit_best(svm_linear_final_tune)\n# \n# svm_linear_final_pred <- predict(svm_linear_final_fit, final_test, type = \"class\")\n# svm_linear_final_acc <- accuracy_vec(final_test$Transported, svm_linear_final_pred$.pred_class)\n# svm_poly_final_mod <- svm_poly(cost = tune(), degree = tune(), scale_factor = tune()) %>%\n#   set_mode(\"classification\") %>%\n#   set_engine(\"kernlab\")\n# \n# svm_poly_final_wf <- glm_final_wf %>%\n#   update_model(svm_poly_final_mod)\n# \n# my_acc <- metric_set(accuracy)\n# svm_poly_ctrl <- control_grid(save_pred = TRUE, save_workflow = TRUE)\n# svm_poly_grid <- expand.grid(cost = c(0.2, 0.6, 1), degree = c(1, 2, 3, 4), scale_factor = 1)\n# \n# # my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# # registerDoSNOW(my_cluster)\n# # \n# # system.time({\n# #   set.seed(8584)\n# #   svm_poly_final_tune <- svm_poly_final_wf %>%\n# #     tune_grid(object = ., resamples = final_folds, metrics = my_acc, control = svm_poly_ctrl, grid = svm_poly_grid)\n# # })\n# # \n# # save(svm_poly_final_tune, file = \"Extra/Final SVM polynomial tune.RData\")\n# # \n# # snow::stopCluster(my_cluster)\n# # unregister()\n# \n# svm_poly_final_tune <- load(\"Extra/Final SVM polynomial tune.RData\")\n# \n# show_best(svm_poly_final_tune, metric = \"accuracy\", n = 20) %>%\n#   ggplot(aes(x = as.factor(cost), y = mean, colour = as.factor(degree))) +\n#   geom_point() +\n#   scale_y_continuous(breaks = seq(0.7, 0.8, 0.01)) +\n#   labs(title = \"Final tune results\", x = \"Cost penalty\", y = \"Resample accuracy\", colour = \"Polynomial\\ndegree\")\n# \n# set.seed(8584)\n# svm_poly_final_fit <- fit_best(svm_poly_final_tune)\n# \n# svm_poly_final_pred <- predict(svm_poly_final_fit, final_test, type = \"class\")\n# svm_poly_final_acc <- accuracy_vec(final_test$Transported, svm_poly_final_pred$.pred_class)\n# svm_rbf_final_mod <- svm_rbf(cost = tune(), degree = tune(), scale_factor = tune()) %>%\n#   set_mode(\"classification\") %>%\n#   set_engine(\"kernlab\")\n# \n# svm_rbf_final_wf <- glm_final_wf %>%\n#   update_model(svm_rbf_final_mod)\n# \n# my_acc <- metric_set(accuracy)\n# svm_rbf_ctrl <- control_grid(save_pred = TRUE, save_workflow = TRUE)\n# svm_rbf_grid <- expand.grid(cost = c(0.2, 0.6, 1), degree = c(1, 2, 3), scale_factor = 1)\n# \n# my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# system.time({\n#   set.seed(8584)\n#   svm_rbf_final_tune <- svm_rbf_final_wf %>%\n#     tune_grid(object = ., resamples = final_folds, metrics = my_acc, control = svm_rbf_ctrl, grid = svm_rbf_grid)\n# })\n# \n# save(svm_rbf_final_tune, file = \"Extra/Final SVM rbf tune.RData\")\n# \n# snow::stopCluster(my_cluster)\n# unregister()\n# \n# load(\"Extra/Final SVM rbf tune.RData\")\n# \n# show_best(svm_rbf_final_tune, metric = \"accuracy\", n = 20) %>%\n#   ggplot(aes(x = cost, y = mean)) +\n#   geom_line() +\n#   geom_point() +\n#   scale_x_continuous(breaks = seq(0, 2, 0.2)) +\n#   labs(title = \"Final tune results\", x = \"Cost penalty\", y = \"Resample accuracy\")\n# \n# set.seed(8584)\n# svm_rbf_final_fit <- fit_best(svm_rbf_final_tune)\n# \n# svm_rbf_final_pred <- predict(svm_rbf_final_fit, final_test, type = \"class\")\n# svm_rbf_final_acc <- accuracy_vec(final_test$Transported, svm_rbf_final_pred$.pred_class)"},{"path":"chapter-8.html","id":"naive-bayes","chapter":"8 Final model tuning","heading":"8.6 Naive Bayes","text":"Naive Bayes model two tuning parameters parsnip package: smoothness Laplace. smoothness parameter controls models class boundaries lower values mean probabilities closely based see training data higher value means probabilities smoothed (imagine points graph: low smoothness draw complex line point high smoothness might draw simple linear line - best fit probably somewhere ).\nLaplace-parameter can used add value probability calculations avoid zero probabilities cases variables low frequency values test data values present training data.","code":"\n# nb_final_mod <- naive_Bayes(smoothness = tune(), Laplace = tune()) %>%\n#   set_engine(\"klaR\") %>%\n#   set_mode(\"classification\")\n# \n# nb_final_wf <- glm_final_wf %>%\n#   update_model(nb_final_mod)\n# \n# my_acc <- metric_set(accuracy)\n# nb_ctrl <- control_grid(save_pred = TRUE, save_workflow = TRUE)\n# nb_grid <- expand.grid(smoothness = seq(0, 5, 0.5), Laplace = 1)\n# \n# my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# system.time({\n#   set.seed(8584)\n#   nb_final_tune <- nb_final_wf %>%\n#     tune_grid(object = ., resamples = final_folds, metrics = my_acc, control = nb_ctrl, grid = nb_grid)\n# })\n# \n# save(nb_final_tune, file = \"Extra/Final Naive Bayes tune.RData\")\n# \n# snow::stopCluster(my_cluster)\n# unregister()\n# \n# load(\"Extra/Final Naive Bayes tune.RData\")\n# \n# show_best(nb_final_tune, metric = \"accuracy\", n = 20) %>%\n#   ggplot(aes(x = cost, y = mean)) +\n#   geom_line() +\n#   geom_point() +\n#   scale_x_continuous(breaks = seq(0, 2, 0.2)) +\n#   labs(title = \"Final tune results\", x = \"Cost penalty\", y = \"Resample accuracy\")\n# \n# set.seed(8584)\n# nb_final_fit <- fit_best(nb_final_tune)\n# \n# nb_final_pred <- predict(nb_final_fit, final_test, type = \"class\")\n# nb_final_acc <- accuracy_vec(final_test$Transported, nb_final_pred$.pred_class)"},{"path":"chapter-8.html","id":"knn","chapter":"8 Final model tuning","heading":"8.7 KNN","text":"’ve already used K-Nearest Neighbours function impute data 3, uses distance measure determine close new observations nearest neighbours. model two tuning parameters parsnip: neighbors weight_func. neighbors-parameter used decide many neighbours used similarity comparison weigh_func-parameter used set kernel used distance measure neighbours. variety kernels choose :Rectangular: also known uniform kernel. gives equal weight neighbors within window, effectively creating binary situation points either neighborhood (given equal weight) .\nTriangular: kernel assigns weights linearly decreasing center. gives maximum weight nearest neighbor minimum weight farthest neighbor within window.\nEpanechnikov: kernel parabolic maximum center, decreasing zero window’s edge. often used minimizes mean integrated square error.\nBiweight: smooth, bell-shaped kernel gives weight nearer neighbors.\nTriweight: similar biweight gives even weight nearer neighbors.\nCos: kernel uses cosine distance weight neighbors.\nInv: kernel gives weights inverse distance.\nGaussian: kernel uses Gaussian function assign weights. bell shape compactly support, meaning gives weight points dataset, weight decreases rapidly distance increases.\nRank: kernel uses ranks distances rather distances .purposes, probably want use rectangular kernel keep simple. ’m sure weighting makes sense type variables response.","code":"\n# knn_final_mod <- nearest_neighbor(neighbors = tune(), weight_func = \"rectangular\") %>%\n#   set_engine(\"kknn\") %>%\n#   set_mode(\"classification\")\n# \n# knn_final_wf <- glm_final_wf %>%\n#   update_model(knn_final_mod)\n# \n# my_acc <- metric_set(accuracy)\n# knn_ctrl <- control_grid(save_pred = TRUE, save_workflow = TRUE)\n# knn_grid <- expand.grid(smoothness = seq(0, 5, 0.5), Laplace = 1)\n# \n# my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# system.time({\n#   set.seed(8584)\n#   knn_final_tune <- knn_final_wf %>%\n#     tune_grid(object = ., resamples = final_folds, metrics = my_acc, control = knn_ctrl, grid = knn_grid)\n# })\n# \n# save(knn_final_tune, file = \"Extra/Final KNN tune.RData\")\n# \n# snow::stopCluster(my_cluster)\n# unregister()\n# \n# load(\"Extra/Final KNN tune.RData\")\n# \n# show_best(knn_final_tune, metric = \"accuracy\", n = 20) %>%\n#   ggplot(aes(x = cost, y = mean)) +\n#   geom_line() +\n#   geom_point() +\n#   scale_x_continuous(breaks = seq(0, 2, 0.2)) +\n#   labs(title = \"Final tune results\", x = \"Cost penalty\", y = \"Resample accuracy\")\n# \n# set.seed(8584)\n# knn_final_fit <- fit_best(knn_final_tune)\n# \n# knn_final_pred <- predict(knn_final_fit, final_test, type = \"class\")\n# knn_final_acc <- accuracy_vec(final_test$Transported, knn_final_pred$.pred_class)"},{"path":"chapter-8.html","id":"c5","chapter":"8 Final model tuning","heading":"8.8 C5","text":"C5.0 model decision trees single tuning parameter parsnip: min_n. parameter sets minimal node size lower boundary many values node must split .","code":"\n# c5.0_final_mod <- decision_tree(min_n = tune()) %>%\n#   set_mode(\"classification\") %>%\n#   set_engine(\"C5.0\")\n# \n# c5.0_final_wf <- glm_final_wf %>%\n#   update_model(c5.0_final_mod)\n# \n# my_acc <- metric_set(accuracy)\n# c5.0_ctrl <- control_grid(save_pred = TRUE, save_workflow = TRUE)\n# c5.0_grid <- expand.grid(min_n = seq(2, 3, 4, 5, 8, 12, 24, 48))\n# \n# my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# system.time({\n#   set.seed(8584)\n#   C5.0_final_tune <- C5.0_final_wf %>%\n#     tune_grid(object = ., resamples = final_folds, metrics = my_acc, control = C5.0_ctrl, grid = C5.0_grid)\n# })\n# \n# save(C5.0_final_tune, file = \"Extra/Final C5_0 tune.RData\")\n# \n# snow::stopCluster(my_cluster)\n# unregister()\n# \n# load(\"Extra/Final C5_0 tune.RData\")\n# \n# show_best(C5.0_final_tune, metric = \"accuracy\", n = 20) %>%\n#   ggplot(aes(x = cost, y = mean)) +\n#   geom_line() +\n#   geom_point() +\n#   scale_x_continuous(breaks = seq(0, 2, 0.2)) +\n#   labs(title = \"Final tune results\", x = \"Cost penalty\", y = \"Resample accuracy\")\n# \n# set.seed(8584)\n# C5.0_final_fit <- fit_best(C5.0_final_tune)\n# \n# C5.0_final_pred <- predict(C5.0_final_fit, final_test, type = \"class\")\n# C5.0_final_acc <- accuracy_vec(final_test$Transported, C5.0_final_pred$.pred_class)"},{"path":"chapter-8.html","id":"randomforest","chapter":"8 Final model tuning","heading":"8.9 RandomForest","text":"model three tuning parameters: mtry, trees min_n. mtry-parameter sets number randomly selected predictors used initiate tree forest tree-parameter sets maximum number trees used. min_n C5.0 model decides lowest number values must present node allowed split.\nleave mtry-parameter default value.","code":"\n# rf_final_mod <- rand_forest(trees = tune(), min_n = tune()) %>%\n#   set_mode(\"classification\") %>%\n#   set_engine(\"randomForest\")\n# \n# rf_final_wf <- glm_final_wf %>%\n#   update_model(rf_final_mod)\n# \n# my_acc <- metric_set(accuracy)\n# rf_ctrl <- control_grid(verbose = TRUE, save_pred = TRUE, save_workflow = TRUE)\n# rf_grid <- expand.grid(trees = c(500, 1000, 5000, 100000, 20000, 30000, 40000), min_n = select_best(C5.0_final_tune))\n# \n# my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# system.time({\n#   set.seed(8584)\n#   rf_final_tune <- rf_final_mod_tune %>%\n#     tune_grid(rf_final_wf, resamples = final_folds, metrics = my_acc, control = rf_ctrl, grid = rf_grid)\n# })\n# \n# save(rf_final_tune, file = \"Extra/Final randomForest tune.RData\")\n# \n# snow::stopCluster(my_cluster)\n# unregister()\n# \n# load(\"Extra/Final randomForest tune.RData\")\n# \n# show_best(rf_final_tune, metric = \"accuracy\", n = 20) %>%\n#   ggplot(aes(x = trees, y = mean)) +\n#   geom_line() +\n#   geom_point() +\n#   scale_x_log10() +\n#   labs(title = \"Tune results for RandomForest\", x = \"Number of trees\", y = \"Resample accuracy\")\n# \n# set.seed(8584)\n# rf_final_fit <- fit_best(rf_final_tune)\n# \n# rf_final_pred <- predict(rf_final_fit, final_test, type = \"class\")\n# rf_final_acc <- accuracy_vec(final_test$Transported, rf_final_pred$.pred_class)"},{"path":"chapter-8.html","id":"xgboost","chapter":"8 Final model tuning","heading":"8.10 XGBoost","text":"XGBoost complicated tree-based model uses boosting iteration, results previous iteration used inputs tweak next ensamble trees. 8 tuning parameters parsnip package: tree_depth, trees, learn_rate, mtry, min_n, loss_reduction, sample_size stop_iter. can use best values previous tree-models leave others defaults.ones tune tree depth, learn-rate loss reduction. tree depth sets maxim number splits within tree. learn-rate determines large steps boosting iterations model takes. larger steps, better performance model may miss important solution. loss reduction determines minimum loss required split node tree. High values lead less overfitting also higher risk underfitting low values increase risk overfitting.","code":"\n# xgb_final_mod <- boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(),\n#                             min_n = select_best(C5.0_final_tune), trees = select_best(rf_final_tune)) %>%\n#   set_engine(\"xgboost\") %>%\n#   set_mode(\"classification\")\n# \n# xgb_final_wf <- glm_final_wf %>%\n#   update_model(xgb_final_mod)\n# \n# my_acc <- metric_set(accuracy)\n# xgb_ctrl <- control_grid(verbose = TRUE, save_pred = TRUE, save_workflow = TRUE)\n# xgb_grid <- expand.grid(tree_depth = seq(3, 9, 1), learn_rate = seq(0.2, 0.4, 0.1), loss_reduction = seq(0, 0.3, 0.1))\n# \n# my_cluster <- snow::makeCluster(detectCores() - 1, type = 'SOCK')\n# registerDoSNOW(my_cluster)\n# \n# system.time({\n#   set.seed(8584)\n#   xgb_final_tune <- xgb_final_mod_tune %>%\n#     tune_grid(xgb_final_wf, resamples = final_folds, metrics = my_acc, control = xgb_ctrl, grid = xgb_grid)\n# })\n# \n# save(xgb_final_tune, file = \"Extra/Final XGBoost tune.RData\")\n# \n# snow::stopCluster(my_cluster)\n# unregister()\n# \n# load(\"Extra/Final XGBoost tune.RData\")\n# \n# show_best(xgb_final_tune, metric = \"accuracy\", n = 20) %>%\n#   ggplot(aes(x = trees, y = mean)) +\n#   geom_line() +\n#   geom_point() +\n#   scale_x_log10() +\n#   labs(title = \"Tune results for RandomForest\", x = \"Number of trees\", y = \"Resample accuracy\")\n# \n# set.seed(8584)\n# xgb_final_fit <- fit_best(xgb_final_tune)\n# \n# xgb_final_pred <- predict(xgb_final_fit, final_test, type = \"class\")\n# xgb_final_acc <- accuracy_vec(final_test$Transported, xgb_final_pred$.pred_class)"},{"path":"chapter-9.html","id":"chapter-9","chapter":"9 Final results","heading":"9 Final results","text":"Let’s make final predictions using far unseen data. , adjust models anymore without risking data leakage.score Kaggle 0.7898 close tuned values. indicates process gives us accurate estimations now must consider can improve select better model.","code":"\n# glm_ultimate_pred <- predict(glm_final_fit, final_test_df, type = \"prob\") %>%\n#   mutate(Prediction = as.factor(if_else(.pred_True < 0.46, \"False\", \"True\")))\n# glm_final_acc <- accuracy_vec(final_test_df$Transported, glm_ultimate_pred$Prediction)\n# \n# glmnet_ultimate_pred <- predict(glmnet_final_fit, final_test_df, type = \"class\")\n# glmnet_final_acc <- accuracy_vec(final_test_df$Transported, glmnet_ultimate_pred$.pred_class)\n# \n# gam_ultimate_pred <- predict(gam_final_fit, final_test_df, type = \"class\")\n# gam_final_acc <- accuracy_vec(final_test_df$Transported, gam_ultimate_pred$.pred_class)\n# \n# svm_linear_ultimate_pred <- predict(svm_linear_final_fit, final_test_df, type = \"class\")\n# svm_linear_final_acc <- accuracy_vec(final_test_df$Transported, svm_linear_ultimate_pred$.pred_class)\n# \n# svm_poly_ultimate_pred <- predict(svm_poly_final_fit, final_test_df, type = \"class\")\n# svm_poly_final_acc <- accuracy_vec(final_test_df$Transported, svm_poly_ultimate_pred$.pred_class)\n# \n# svm_rbf_ultimate_pred <- predict(svm_rbf_final_fit, final_test_df, type = \"class\")\n# svm_rbf_final_acc <- accuracy_vec(final_test_df$Transported, svm_rbf_ultimate_pred$.pred_class)\n# \n# nb_ultimate_pred <- predict(nb_final_fit, final_test_df, type = \"class\")\n# nb_final_acc <- accuracy_vec(final_test_df$Transported, nb_ultimate_pred$.pred_class)\n# \n# knn_ultimate_pred <- predict(knn_final_fit, final_test_df, type = \"class\")\n# knn_final_acc <- accuracy_vec(final_test_df$Transported, knn_ultimate_pred$.pred_class)\n# \n# C5.0_ultimate_pred <- predict(C5.0_final_fit, final_test_df, type = \"class\")\n# C5.0_final_acc <- accuracy_vec(final_test_df$Transported, C5.0_ultimate_pred$.pred_class)\n# \n# rf_ultimate_pred <- predict(rf_final_fit, final_test_df, type = \"class\")\n# rf_final_acc <- accuracy_vec(final_test_df$Transported, rf_ultimate_pred$.pred_class)\n# \n# xgb_ultimate_pred <- predict(xgb_final_fit, final_test_df, type = \"class\")\n# xgb_final_acc <- accuracy_vec(final_test_df$Transported, xgb_ultimate_pred$.pred_class)"}]
