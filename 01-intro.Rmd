# Early data exploration
```{r setup, include = FALSE}
library(tidyverse)
library(tidymodels)
library(caret)
library(sjPlot)
library(DataExplorer)
library(visdat)
library(skimr)
library(naniar)
library(ggstats)
library(ggthemes)
library(gridExtra)
library(mgcv)
library(vcd)
library(FactoMineR)
library(factoextra)
library(colorspace)
library(missRanger)
library(rpart)
library(dlookr)
library(embed)
library(pre)
library(parallel)
library(doSNOW)
library(janitor)
library(rFSA)
library(bslib)
library(showtext)
library(forcats)
library(interactions)
library(foreach)
library(cowplot)
library(patchwork)
library(R.utils)
library(glue)
library(Matrix)
library(ranger)
library(glmnet)
library(pls)

theme_set(theme_clean(base_size = 10))

unregister <- function() { # Helper function to unregister parallel processes that didn't shut down for some reason
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}
```

## Overview of the data
The data has already been divided into train and test sets so let's load them and get a sense of how the *train* data looks like. We'll also try to be very strict with the machine learning principles and not touch or even look at the *test* data until the end. 

Let's first get a sense of the train data.
```{r overview}
train <- read.csv("train.csv", na.strings = "")
str(train)
```

There are 8693 observations and 14 variables where "Transported" is the target variable. The specifics on the different variables are explained in detail on the competition website so I won't repeat them here. It's enough to note that there is a mix of categorical and continuous variables and that our target variable is expressed as True/False in a character vector.

## Do some variables have zero or near-zero variance?
One of the first things that might be useful to check is whether any of the variables have zero or near-zero variance. A zero variance variable is one where all rows have the same value (imagine a variable where all rows are just the number 1). Such variables are not useful for prediction since they don't change regardless of how the target variable changes.

Their close cousin are the near-zero variances where a high percentage of the rows have the same value but some don't. This can be particularly problematic when we want to do repeated cross validation where we divide the data into subdata to test our models. Some of these subdata might then have zero variance while other subdata might get a high variance for the same variable. 
```{r variance}
nearZeroVar(train, saveMetrics = TRUE) %>% rownames_to_column() %>% filter(nzv)
```

Only the VIP variable has near-zero variation (2.3% of all rows). We'll deal with this later.

## Frequency distribution of all variables
Let's see how the values of the different variables are distributed.
```{r frequencies, results = "hide", fig.cap = "Distribution of the variables against the response"}
plot_frq(train, Transported)
plot_frq(train, -Transported, type = "histogram")
```

The target variable is balanced which is preferable. An unbalanced distribution of the target variable (meaning that the share of one outcome vastly outweighs the other) can skew the predictive results of some algorithms. Fortunately, we do not have to apply any resampling or downsampling methods to balance it.

The numeric variables are right-skewed, meaning they have outliers to the right of the horizontal axis and the amenities (RoomService, FoodCourt etc) have a high proportion of zero values. The difference in scales is also large. We will need to apply some kind of preproces to scale them to help out models like K-nearest-neighbors (KNN). We might also need to add binary features (yes/no or 1/0) for the amenities that are zero.

The Cabin and Name variables have a near uniform distribution which implies that they either won't have much predictive power by themselves or could even reduce the accuracy by introducing unnecessary noise to the model. We will either have to derive features from these variables or not include them in the models.

## Correlation between the variables
```{r correlation, results = "hide", warning = FALSE, fig.cap = "Correlation between numerical variables"}
train %>%
  na.omit(.) %>%
plot_correlation(., type = "all",
                 geom_text_args = list(size = 2),
                 theme_config = list(axis.text.x = element_text(angle = 90)))
```

We see that there's some relatively high correlation between homeplanets and destinations as well as a moderate correlation between CryoSleep and Transported which already gives us a hint that CryoSleep might be important. Otherwise, the cariables seem relatively uncorrelated which is a good thing since some models cannot handle variables that are too correlated.

## Overview of missing values
```{r missing, fig.cap = "Missing values overview"}
plot_na_hclust(train)
```

All predictor variables are missing to the amount of 2% which is relatively low. When we cluster the missing values, we can also see that most don't overlap which suggests that they're missing at random and not due to some specific pattern. This tells us that we can probably find a suitable algorithm to help us impute the missing values based on the non-missing values. Had there been a pattern or clusters of missing data, we'd have to explore further to uncover the reasons for such non-random missingness.